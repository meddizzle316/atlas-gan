{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-21T17:11:16.738208Z",
     "start_time": "2024-10-21T17:11:16.734781Z"
    }
   },
   "source": [
    "import torch.nn as nn\n",
    "import torch "
   ],
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T17:11:16.754536Z",
     "start_time": "2024-10-21T17:11:16.751210Z"
    }
   },
   "cell_type": "code",
   "source": "print(torch.__version__)",
   "id": "9dc942bfe103e1c0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1+cu124\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T17:11:16.867863Z",
     "start_time": "2024-10-21T17:11:16.864970Z"
    }
   },
   "cell_type": "code",
   "source": "print(torch.cuda.is_available())",
   "id": "137b405b8ec86171",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T17:11:16.895697Z",
     "start_time": "2024-10-21T17:11:16.891867Z"
    }
   },
   "cell_type": "code",
   "source": "print(torch.version.cuda)",
   "id": "d152c5800b640b48",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.4\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T17:11:17.012492Z",
     "start_time": "2024-10-21T17:11:17.009372Z"
    }
   },
   "cell_type": "code",
   "source": "tensor_cpu = torch.randn(3, 3)",
   "id": "5629e1d8ea31d4b3",
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T17:11:17.024686Z",
     "start_time": "2024-10-21T17:11:17.020494Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.cuda.empty_cache()\n",
    "tensor_gpu = tensor_cpu.to('cuda')"
   ],
   "id": "c2e24cd9d00a17f5",
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T17:11:17.101280Z",
     "start_time": "2024-10-21T17:11:17.096685Z"
    }
   },
   "cell_type": "code",
   "source": "print(tensor_gpu.device)",
   "id": "54aa193243890f6a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T17:11:17.169628Z",
     "start_time": "2024-10-21T17:11:17.165505Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torchvision\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as dataloader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n"
   ],
   "id": "d96150f2a15503f9",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T17:11:17.226633Z",
     "start_time": "2024-10-21T17:11:17.223395Z"
    }
   },
   "cell_type": "code",
   "source": "from torchsummary import summary",
   "id": "a7298068a58d0f9e",
   "outputs": [],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T18:50:27.955688Z",
     "start_time": "2024-10-21T18:50:27.931543Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, channels_img, features_d):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            # is the convention for Conv in pytorch N, channels, height, width?\n",
    "            nn.Conv2d(channels_img, features_d, kernel_size=4, stride=2, padding=1), # what does padding 1 correspond to?\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            nn.Conv2d(features_d, features_d * 2, kernel_size=4, stride=2, padding=1), # why features_d for filters? Why features_d * 2?\n",
    "            nn.BatchNorm2d(features_d * 2), # because GANS are known for being notoriously unstable during training -- why are GANS known for this?\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            nn.Conv2d(features_d *2, features_d * 4, kernel_size=4, stride=2, padding=1), \n",
    "            nn.BatchNorm2d(features_d * 4), \n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(features_d * 4, features_d * 8, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(features_d * 8),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            # N x features_d * 8 x 4 x 4\n",
    "            nn.Conv2d(features_d * 8, 1, kernel_size=4, stride=2, padding=0),\n",
    "            \n",
    "            # N x 1 x 1 x 1\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "    \n"
   ],
   "id": "f86d46c295864940",
   "outputs": [],
   "execution_count": 71
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T19:05:26.263530Z",
     "start_time": "2024-10-21T19:05:26.249801Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, channels_noise, channels_img, features_g):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "            # Output_size=(Input_size−1)×stride−2×padding+kernel_size\n",
    "            \n",
    "            # N x channels_noise x 1 x 1\n",
    "            \n",
    "            nn.ConvTranspose2d(channels_noise, features_g * 16, kernel_size=5, stride=1, padding=0), \n",
    "            nn.BatchNorm2d(features_g * 16),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            # N x 256 x 5 x 5\n",
    "            \n",
    "            nn.ConvTranspose2d(features_g * 16, features_g * 8, kernel_size=8, stride=3, padding=0),\n",
    "            nn.BatchNorm2d(features_g * 8),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            # N x 128 x 20 x 20\n",
    "        \n",
    "            nn.ConvTranspose2d(features_g * 8, channels_img, kernel_size=7, stride=3, padding=0),\n",
    "            \n",
    "            # N x channels_img # 64 x 64\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ],
   "id": "8c8407fe0a2f6c65",
   "outputs": [],
   "execution_count": 91
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T17:11:17.390576Z",
     "start_time": "2024-10-21T17:11:17.387796Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lr = 0.0002\n",
    "batch_size = 64\n",
    "image_size = 64 # 28 x 28 >>> 64x64\n",
    "channels_img = 1 # since grayscale images\n",
    "channels_noise = 256\n",
    "\n",
    "features_d = 16 # was set at 64 in the paper but not needed for mnist might for celebrity faces though\n",
    "features_g = 16 # was set at 64 in the paper but not needed for mnist might for celebrity faces though"
   ],
   "id": "5fbde815fb0b2678",
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T17:11:17.441523Z",
     "start_time": "2024-10-21T17:11:17.438008Z"
    }
   },
   "cell_type": "code",
   "source": [
    "my_transforms = transforms.Compose([ # what does the transforms do in pytorch??\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,)),\n",
    "])"
   ],
   "id": "815cd660a175607c",
   "outputs": [],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T17:11:17.556623Z",
     "start_time": "2024-10-21T17:11:17.491653Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = datasets.MNIST(root='dataset/', train=True, transform=my_transforms, download=True) # seems to download the specified dataset to my directory\n",
    "my_dataloader  = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True) # not sure what's going on thought I already imported this?\n"
   ],
   "id": "d0f0f89ecd3793b7",
   "outputs": [],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T17:11:17.610491Z",
     "start_time": "2024-10-21T17:11:17.607344Z"
    }
   },
   "cell_type": "code",
   "source": "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
   "id": "dbc35f8de6c91776",
   "outputs": [],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T17:11:17.704061Z",
     "start_time": "2024-10-21T17:11:17.664994Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create discriminator and generator\n",
    "\n",
    "netD = Discriminator(channels_img, features_d).to(device) #  Iguess every model has to be specified to a device? So I could run some on different gpus or my cpu? \n",
    "netG = Generator(channels_noise, channels_img, features_g).to(device)"
   ],
   "id": "305e2080cd6e3b24",
   "outputs": [],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T17:11:17.758280Z",
     "start_time": "2024-10-21T17:11:17.755149Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Setup Optimizer for G and D\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(0.5, 0.999)) # why are we specifying? What is the default betas value? 0.9 and 0.999?\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(0.5, 0.999))"
   ],
   "id": "396764a0e16d0f28",
   "outputs": [],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T19:05:31.312034Z",
     "start_time": "2024-10-21T19:05:31.010762Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create discriminator and generator\n",
    "\n",
    "netD = Discriminator(channels_img, features_d).to(device) #  Iguess every model has to be specified to a device? So I could run some on different gpus or my cpu? \n",
    "netG = Generator(channels_noise, channels_img, features_g).to(device)\n",
    "\n",
    "# check shape of generator houtput\n",
    "num_images = 32\n",
    "\n",
    "with torch.no_grad():\n",
    "    noise = torch.randn(num_images, channels_noise, 1, 1).to(device)\n",
    "    fake_images = netG(noise).to(device)\n",
    "print(fake_images.shape)\n",
    "\n",
    "summary(netG, input_size=(channels_noise, 1, 1))"
   ],
   "id": "c38fdcca3ba1a735",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 64, 64])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "   ConvTranspose2d-1            [-1, 256, 5, 5]       1,638,656\n",
      "       BatchNorm2d-2            [-1, 256, 5, 5]             512\n",
      "              ReLU-3            [-1, 256, 5, 5]               0\n",
      "   ConvTranspose2d-4          [-1, 128, 20, 20]       2,097,280\n",
      "       BatchNorm2d-5          [-1, 128, 20, 20]             256\n",
      "              ReLU-6          [-1, 128, 20, 20]               0\n",
      "   ConvTranspose2d-7            [-1, 1, 64, 64]           6,273\n",
      "              Tanh-8            [-1, 1, 64, 64]               0\n",
      "================================================================\n",
      "Total params: 3,742,977\n",
      "Trainable params: 3,742,977\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 1.38\n",
      "Params size (MB): 14.28\n",
      "Estimated Total Size (MB): 15.66\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 92
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T19:05:58.345146Z",
     "start_time": "2024-10-21T19:05:58.327974Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "netD.train() # what is the difference being in training mode from otherwise in pytorch?"
   ],
   "id": "1e043c6a90181cff",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (net): Sequential(\n",
       "    (0): Conv2d(1, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.2)\n",
       "    (2): Conv2d(16, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): LeakyReLU(negative_slope=0.2)\n",
       "    (5): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): LeakyReLU(negative_slope=0.2)\n",
       "    (8): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): LeakyReLU(negative_slope=0.2)\n",
       "    (11): Conv2d(128, 1, kernel_size=(4, 4), stride=(2, 2))\n",
       "    (12): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 93
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T19:06:02.178835Z",
     "start_time": "2024-10-21T19:06:02.165310Z"
    }
   },
   "cell_type": "code",
   "source": "netG.train() # apparently the models should be in training mode by default but we're doing it explicitly",
   "id": "f6f362d3c428d92e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (net): Sequential(\n",
       "    (0): ConvTranspose2d(256, 256, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): ConvTranspose2d(256, 128, kernel_size=(8, 8), stride=(3, 3))\n",
       "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): ConvTranspose2d(128, 1, kernel_size=(7, 7), stride=(3, 3))\n",
       "    (7): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 94
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T17:11:17.948416Z",
     "start_time": "2024-10-21T17:11:17.945435Z"
    }
   },
   "cell_type": "code",
   "source": "criterion = nn.BCELoss() # binary cross entropy -- should probably ask why this specific loss function?",
   "id": "49dae3fcf107a6c3",
   "outputs": [],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T17:11:18.048197Z",
     "start_time": "2024-10-21T17:11:18.045730Z"
    }
   },
   "cell_type": "code",
   "source": [
    "real_label = 1\n",
    "fake_label = 0"
   ],
   "id": "c42132f3e272208b",
   "outputs": [],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T17:11:18.059558Z",
     "start_time": "2024-10-21T17:11:18.054200Z"
    }
   },
   "cell_type": "code",
   "source": "fixed_noise = torch.randn(64, channels_noise, 1, 1).to(device)",
   "id": "1cf6a8e05dcfa525",
   "outputs": [],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T17:11:18.114190Z",
     "start_time": "2024-10-21T17:11:18.111748Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torchvision.transforms import ToPILImage\n",
    "import torchvision.utils as vutils"
   ],
   "id": "159eef8860ee7471",
   "outputs": [],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T19:23:02.812078Z",
     "start_time": "2024-10-21T19:07:37.957443Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"starting training...\")\n",
    "num_epochs = 10\n",
    "img_idx = 0\n",
    "\n",
    "# writer_real = SummaryWriter(log_dir='runs/GAN_MNIST/log_real')\n",
    "# writer_fake = SummaryWriter(log_dir='runs/GAN_MNIST/log_fake')\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (data, targets) in enumerate(my_dataloader):\n",
    "        data = data.to(device)\n",
    "        batch_size = data.shape[0]\n",
    "        # apparently it's important that we train the Discriminator first\n",
    "        # Train Discriminator : max log (D(x)) + log(1-D(G(z)))\n",
    "        # We send in all real images first\n",
    "        netD.zero_grad()\n",
    "        label = (torch.ones(batch_size)*0.9).to(device) # apparently 0.9 helps? Would like to look at that again\n",
    "        output = netD(data).reshape(-1)\n",
    "        \n",
    "        lossD_real = criterion(output, label)\n",
    "        D_x = output.mean().item() # for evaluation purposes, could do something similar with the other models to get \n",
    "        \n",
    "        # now we send in all fake images to the discriminator\n",
    "        noise = torch.randn(batch_size, channels_noise, 1, 1).to(device)\n",
    "        fake = netG(noise)\n",
    "        label = (torch.ones(batch_size)*0.1).to(device) # would what to look at this again\n",
    "        \n",
    "        output = netD(fake.detach()).reshape(-1) # telling pytorch not to trace the gradients? Not exactly sure, does that mean we're not training the generator? \n",
    "        lossD_fake = criterion(output, label)\n",
    "        \n",
    "        lossD = lossD_real + lossD_fake\n",
    "        lossD.backward() # not sure what these are doing -- look this up\n",
    "        optimizerD.step() # need to ask about this\n",
    "        \n",
    "        # Train Generator: min log(1 - D(G(z)))\n",
    "        netG.zero_grad()\n",
    "        label = torch.ones(batch_size).to(device) # not multiplying by 0.9 here\n",
    "        output = netD(fake).reshape(-1) # we actually want to train the generator now? So we don't do detach?\n",
    "        lossG = criterion(output, label)\n",
    "        lossG.backward()\n",
    "        optimizerG.step()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f\"Epoch [{epoch}/{num_epochs}] Batch {batch_idx}/{len(my_dataloader)} \\\n",
    "             Loss D: {lossD:.4f}, Loss G: {lossG:.4f}, D(x): {D_x:.4f}\")\n",
    "            \n",
    "            with torch.no_grad(): # what is happening here?\n",
    "                fake = netG(fixed_noise)\n",
    "                \n",
    "                img_grid_real = torchvision.utils.make_grid(data[:32], normalize=True)\n",
    "                img_grid_fake = torchvision.utils.make_grid(fake[:32], normalize=True)\n",
    "                # writer_real.add_image('MNIST Real Images', img_grid_real)\n",
    "                # writer_fake.add_image('MNIST Fake Images', img_grid_fake)\n",
    "                \n",
    "                #since Tensorboard site is still being allowed, I'll provide a locall method of viewing the pictures\n",
    "                to_pil = ToPILImage()\n",
    "                \n",
    "                img_real = to_pil(img_grid_real)\n",
    "                img_real.save(f'../images/experiment1/real/real_images_grid_{img_idx}.png')\n",
    "                \n",
    "                img_fake = to_pil(img_grid_fake)\n",
    "                img_fake.save(f'../images/experiment1/fake/fake_images_grid_{img_idx}.png')\n",
    "                img_idx += 1\n",
    "        "
   ],
   "id": "4e8594e0da17b164",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting training...\n",
      "Epoch [0/10] Batch 0/938              Loss D: 1.5341, Loss G: 0.5156, D(x): 0.5398\n",
      "Epoch [0/10] Batch 100/938              Loss D: 1.6159, Loss G: 0.4502, D(x): 0.5470\n",
      "Epoch [0/10] Batch 200/938              Loss D: 1.5802, Loss G: 0.4842, D(x): 0.5395\n",
      "Epoch [0/10] Batch 300/938              Loss D: 1.5460, Loss G: 0.5133, D(x): 0.5398\n",
      "Epoch [0/10] Batch 400/938              Loss D: 1.6027, Loss G: 0.4795, D(x): 0.5270\n",
      "Epoch [0/10] Batch 500/938              Loss D: 1.5821, Loss G: 0.4894, D(x): 0.5312\n",
      "Epoch [0/10] Batch 600/938              Loss D: 1.5983, Loss G: 0.4789, D(x): 0.5342\n",
      "Epoch [0/10] Batch 700/938              Loss D: 1.5242, Loss G: 0.5065, D(x): 0.5549\n",
      "Epoch [0/10] Batch 800/938              Loss D: 1.5734, Loss G: 0.4893, D(x): 0.5409\n",
      "Epoch [0/10] Batch 900/938              Loss D: 1.6130, Loss G: 0.4804, D(x): 0.5228\n",
      "Epoch [1/10] Batch 0/938              Loss D: 1.5605, Loss G: 0.4855, D(x): 0.5472\n",
      "Epoch [1/10] Batch 100/938              Loss D: 1.6057, Loss G: 0.4695, D(x): 0.5387\n",
      "Epoch [1/10] Batch 200/938              Loss D: 1.5768, Loss G: 0.4891, D(x): 0.5335\n",
      "Epoch [1/10] Batch 300/938              Loss D: 1.5524, Loss G: 0.5013, D(x): 0.5463\n",
      "Epoch [1/10] Batch 400/938              Loss D: 1.5763, Loss G: 0.4789, D(x): 0.5434\n",
      "Epoch [1/10] Batch 500/938              Loss D: 1.5923, Loss G: 0.4743, D(x): 0.5408\n",
      "Epoch [1/10] Batch 600/938              Loss D: 1.5566, Loss G: 0.4958, D(x): 0.5420\n",
      "Epoch [1/10] Batch 700/938              Loss D: 1.5647, Loss G: 0.4921, D(x): 0.5414\n",
      "Epoch [1/10] Batch 800/938              Loss D: 1.5868, Loss G: 0.4700, D(x): 0.5485\n",
      "Epoch [1/10] Batch 900/938              Loss D: 1.5907, Loss G: 0.4754, D(x): 0.5487\n",
      "Epoch [2/10] Batch 0/938              Loss D: 1.5996, Loss G: 0.4820, D(x): 0.5290\n",
      "Epoch [2/10] Batch 100/938              Loss D: 1.5433, Loss G: 0.5016, D(x): 0.5486\n",
      "Epoch [2/10] Batch 200/938              Loss D: 1.5878, Loss G: 0.4797, D(x): 0.5345\n",
      "Epoch [2/10] Batch 300/938              Loss D: 1.5759, Loss G: 0.4843, D(x): 0.5449\n",
      "Epoch [2/10] Batch 400/938              Loss D: 1.5761, Loss G: 0.4935, D(x): 0.5298\n",
      "Epoch [2/10] Batch 500/938              Loss D: 1.6186, Loss G: 0.4594, D(x): 0.5331\n",
      "Epoch [2/10] Batch 600/938              Loss D: 1.6369, Loss G: 0.4638, D(x): 0.5184\n",
      "Epoch [2/10] Batch 700/938              Loss D: 1.6182, Loss G: 0.4660, D(x): 0.5303\n",
      "Epoch [2/10] Batch 800/938              Loss D: 1.5642, Loss G: 0.4851, D(x): 0.5432\n",
      "Epoch [2/10] Batch 900/938              Loss D: 1.5877, Loss G: 0.4787, D(x): 0.5418\n",
      "Epoch [3/10] Batch 0/938              Loss D: 1.6135, Loss G: 0.4734, D(x): 0.5357\n",
      "Epoch [3/10] Batch 100/938              Loss D: 1.5841, Loss G: 0.4819, D(x): 0.5373\n",
      "Epoch [3/10] Batch 200/938              Loss D: 1.6004, Loss G: 0.4558, D(x): 0.5491\n",
      "Epoch [3/10] Batch 300/938              Loss D: 1.5393, Loss G: 0.5126, D(x): 0.5378\n",
      "Epoch [3/10] Batch 400/938              Loss D: 1.5739, Loss G: 0.4831, D(x): 0.5408\n",
      "Epoch [3/10] Batch 500/938              Loss D: 1.5608, Loss G: 0.4913, D(x): 0.5406\n",
      "Epoch [3/10] Batch 600/938              Loss D: 1.5742, Loss G: 0.4793, D(x): 0.5484\n",
      "Epoch [3/10] Batch 700/938              Loss D: 1.6132, Loss G: 0.4573, D(x): 0.5402\n",
      "Epoch [3/10] Batch 800/938              Loss D: 1.5581, Loss G: 0.5003, D(x): 0.5436\n",
      "Epoch [3/10] Batch 900/938              Loss D: 1.6136, Loss G: 0.4626, D(x): 0.5351\n",
      "Epoch [4/10] Batch 0/938              Loss D: 1.6059, Loss G: 0.4700, D(x): 0.5351\n",
      "Epoch [4/10] Batch 100/938              Loss D: 1.6146, Loss G: 0.4730, D(x): 0.5239\n",
      "Epoch [4/10] Batch 200/938              Loss D: 1.5753, Loss G: 0.4845, D(x): 0.5391\n",
      "Epoch [4/10] Batch 300/938              Loss D: 1.5622, Loss G: 0.4932, D(x): 0.5440\n",
      "Epoch [4/10] Batch 400/938              Loss D: 1.5623, Loss G: 0.4976, D(x): 0.5413\n",
      "Epoch [4/10] Batch 500/938              Loss D: 1.5930, Loss G: 0.4790, D(x): 0.5328\n",
      "Epoch [4/10] Batch 600/938              Loss D: 1.5654, Loss G: 0.4937, D(x): 0.5415\n",
      "Epoch [4/10] Batch 700/938              Loss D: 1.5904, Loss G: 0.4804, D(x): 0.5384\n",
      "Epoch [4/10] Batch 800/938              Loss D: 1.5593, Loss G: 0.4943, D(x): 0.5450\n",
      "Epoch [4/10] Batch 900/938              Loss D: 1.6077, Loss G: 0.4666, D(x): 0.5378\n",
      "Epoch [5/10] Batch 0/938              Loss D: 1.5737, Loss G: 0.4741, D(x): 0.5537\n",
      "Epoch [5/10] Batch 100/938              Loss D: 1.5356, Loss G: 0.5184, D(x): 0.5435\n",
      "Epoch [5/10] Batch 200/938              Loss D: 1.5215, Loss G: 0.5167, D(x): 0.5477\n",
      "Epoch [5/10] Batch 300/938              Loss D: 1.5977, Loss G: 0.4840, D(x): 0.5336\n",
      "Epoch [5/10] Batch 400/938              Loss D: 1.5879, Loss G: 0.4742, D(x): 0.5497\n",
      "Epoch [5/10] Batch 500/938              Loss D: 1.5649, Loss G: 0.4728, D(x): 0.5568\n",
      "Epoch [5/10] Batch 600/938              Loss D: 1.5727, Loss G: 0.4850, D(x): 0.5436\n",
      "Epoch [5/10] Batch 700/938              Loss D: 1.6077, Loss G: 0.4664, D(x): 0.5389\n",
      "Epoch [5/10] Batch 800/938              Loss D: 1.5404, Loss G: 0.5176, D(x): 0.5455\n",
      "Epoch [5/10] Batch 900/938              Loss D: 1.6231, Loss G: 0.4719, D(x): 0.5216\n",
      "Epoch [6/10] Batch 0/938              Loss D: 1.5849, Loss G: 0.4772, D(x): 0.5480\n",
      "Epoch [6/10] Batch 100/938              Loss D: 1.5798, Loss G: 0.4829, D(x): 0.5439\n",
      "Epoch [6/10] Batch 200/938              Loss D: 1.6223, Loss G: 0.4469, D(x): 0.5471\n",
      "Epoch [6/10] Batch 300/938              Loss D: 1.5636, Loss G: 0.4990, D(x): 0.5379\n",
      "Epoch [6/10] Batch 400/938              Loss D: 1.6149, Loss G: 0.4698, D(x): 0.5329\n",
      "Epoch [6/10] Batch 500/938              Loss D: 1.5887, Loss G: 0.4751, D(x): 0.5386\n",
      "Epoch [6/10] Batch 600/938              Loss D: 1.5585, Loss G: 0.4866, D(x): 0.5546\n",
      "Epoch [6/10] Batch 700/938              Loss D: 1.6018, Loss G: 0.4749, D(x): 0.5349\n",
      "Epoch [6/10] Batch 800/938              Loss D: 1.5891, Loss G: 0.4753, D(x): 0.5434\n",
      "Epoch [6/10] Batch 900/938              Loss D: 1.5856, Loss G: 0.4791, D(x): 0.5348\n",
      "Epoch [7/10] Batch 0/938              Loss D: 1.6441, Loss G: 0.4492, D(x): 0.5231\n",
      "Epoch [7/10] Batch 100/938              Loss D: 1.5623, Loss G: 0.4890, D(x): 0.5483\n",
      "Epoch [7/10] Batch 200/938              Loss D: 1.5675, Loss G: 0.4722, D(x): 0.5564\n",
      "Epoch [7/10] Batch 300/938              Loss D: 1.6115, Loss G: 0.4758, D(x): 0.5243\n",
      "Epoch [7/10] Batch 400/938              Loss D: 1.6219, Loss G: 0.4592, D(x): 0.5341\n",
      "Epoch [7/10] Batch 500/938              Loss D: 1.5969, Loss G: 0.4779, D(x): 0.5308\n",
      "Epoch [7/10] Batch 600/938              Loss D: 1.5901, Loss G: 0.4740, D(x): 0.5364\n",
      "Epoch [7/10] Batch 700/938              Loss D: 1.5907, Loss G: 0.4863, D(x): 0.5296\n",
      "Epoch [7/10] Batch 800/938              Loss D: 1.5591, Loss G: 0.4917, D(x): 0.5454\n",
      "Epoch [7/10] Batch 900/938              Loss D: 1.5469, Loss G: 0.4975, D(x): 0.5466\n",
      "Epoch [8/10] Batch 0/938              Loss D: 1.5598, Loss G: 0.4929, D(x): 0.5463\n",
      "Epoch [8/10] Batch 100/938              Loss D: 1.6364, Loss G: 0.4572, D(x): 0.5214\n",
      "Epoch [8/10] Batch 200/938              Loss D: 1.6077, Loss G: 0.4800, D(x): 0.5258\n",
      "Epoch [8/10] Batch 300/938              Loss D: 1.6247, Loss G: 0.4726, D(x): 0.5205\n",
      "Epoch [8/10] Batch 400/938              Loss D: 1.5896, Loss G: 0.4781, D(x): 0.5382\n",
      "Epoch [8/10] Batch 500/938              Loss D: 1.5891, Loss G: 0.4876, D(x): 0.5305\n",
      "Epoch [8/10] Batch 600/938              Loss D: 1.5711, Loss G: 0.4776, D(x): 0.5513\n",
      "Epoch [8/10] Batch 700/938              Loss D: 1.5597, Loss G: 0.4763, D(x): 0.5604\n",
      "Epoch [8/10] Batch 800/938              Loss D: 1.6197, Loss G: 0.4671, D(x): 0.5317\n",
      "Epoch [8/10] Batch 900/938              Loss D: 1.6104, Loss G: 0.4705, D(x): 0.5323\n",
      "Epoch [9/10] Batch 0/938              Loss D: 1.5791, Loss G: 0.4829, D(x): 0.5393\n",
      "Epoch [9/10] Batch 100/938              Loss D: 1.6038, Loss G: 0.4659, D(x): 0.5365\n",
      "Epoch [9/10] Batch 200/938              Loss D: 1.5625, Loss G: 0.5044, D(x): 0.5394\n",
      "Epoch [9/10] Batch 300/938              Loss D: 1.5941, Loss G: 0.4681, D(x): 0.5482\n",
      "Epoch [9/10] Batch 400/938              Loss D: 1.5999, Loss G: 0.4724, D(x): 0.5326\n",
      "Epoch [9/10] Batch 500/938              Loss D: 1.5792, Loss G: 0.4889, D(x): 0.5351\n",
      "Epoch [9/10] Batch 600/938              Loss D: 1.5984, Loss G: 0.4982, D(x): 0.5154\n",
      "Epoch [9/10] Batch 700/938              Loss D: 1.5943, Loss G: 0.4913, D(x): 0.5297\n",
      "Epoch [9/10] Batch 800/938              Loss D: 1.5953, Loss G: 0.4879, D(x): 0.5256\n",
      "Epoch [9/10] Batch 900/938              Loss D: 1.5709, Loss G: 0.4807, D(x): 0.5456\n"
     ]
    }
   ],
   "execution_count": 97
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T19:23:04.553307Z",
     "start_time": "2024-10-21T19:23:02.834603Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torchvision.models import inception_v3\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Load pre-trained Inception v3 model\n",
    "inception_model = inception_v3(pretrained=True, transform_input=False).eval().to(device)"
   ],
   "id": "b4bbdb6199610e9",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\meddi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\meddi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Inception_V3_Weights.IMAGENET1K_V1`. You can also use `weights=Inception_V3_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "execution_count": 98
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T19:23:05.272343Z",
     "start_time": "2024-10-21T19:23:05.250337Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_inception_score(rgb_images, inception_model, splits=10):\n",
    "    # rgb_images = images.repeat(1, 3, 1, 1) # not necessary since I'm doing that before\n",
    "    \n",
    "    rgb_images_resized = F.interpolate(rgb_images, size=(299, 299), mode='bilinear', align_corners=False)\n",
    "    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        preds = inception_model(rgb_images_resized).softmax(dim=1)\n",
    "        \n",
    "    split_scores = []\n",
    "    for i in range(splits):\n",
    "        part = preds[i * (len(preds) // splits): ((i + 1) * len(preds) // splits), :]\n",
    "        p_y = part.mean(dim=0)\n",
    "        split_scores.append(torch.exp((part * (part.log() - p_y.log())).sum(dim=1).mean()))\n",
    "        \n",
    "    return torch.mean(torch.tensor(split_scores)), torch.std(torch.tensor(split_scores))"
   ],
   "id": "35da5b642c9af803",
   "outputs": [],
   "execution_count": 99
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T19:23:06.213820Z",
     "start_time": "2024-10-21T19:23:06.200327Z"
    }
   },
   "cell_type": "code",
   "source": "import numpy as np",
   "id": "ba2f88762984cfb0",
   "outputs": [],
   "execution_count": 100
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T19:23:06.565542Z",
     "start_time": "2024-10-21T19:23:06.555693Z"
    }
   },
   "cell_type": "code",
   "source": "from scipy import linalg",
   "id": "42ee06839d178a5e",
   "outputs": [],
   "execution_count": 101
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T19:23:06.683799Z",
     "start_time": "2024-10-21T19:23:06.613148Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_images = 32\n",
    "\n",
    "first_batch = next(iter(my_dataloader))\n",
    "\n",
    "real_images = first_batch[0]\n",
    "real_images = real_images[:num_images]\n",
    "real_images = (real_images + 1) / 2\n",
    "rgb_real_images = real_images.repeat(1, 3, 1, 1)\n",
    "rgb_real_images = rgb_real_images.to(device)\n",
    "print(\"rgb_real_images shape: \", rgb_real_images.shape)\n",
    "\n",
    "with torch.no_grad():\n",
    "    noise = torch.randn(num_images, channels_noise, 1, 1).to(device)\n",
    "    fake_images = netG(noise).to(device)\n",
    "\n",
    "    fake_images = (fake_images + 1) / 2\n",
    "    rgb_fake_images = fake_images.repeat(1, 3, 1, 1)\n",
    "    \n",
    "print(\"rgb_fake_images shape, \", rgb_fake_images.shape)\n",
    "    "
   ],
   "id": "46e50507c0b0e18d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rgb_real_images shape:  torch.Size([32, 3, 64, 64])\n",
      "rgb_fake_images shape,  torch.Size([32, 3, 64, 64])\n"
     ]
    }
   ],
   "execution_count": 102
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T19:23:07.186726Z",
     "start_time": "2024-10-21T19:23:07.170590Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_activation_statistics(images, model, dims=2048, batch_size=128):\n",
    "    model.eval()\n",
    "    act = np.empty((len(images), dims))\n",
    "    \n",
    "    batch = images.cuda()\n",
    "    \n",
    "    pred = model(batch)[0]\n",
    "    \n",
    "    # if pred.size(2) != 1 or pred.size(3) != 1:\n",
    "    #     # pred = adaptive_avg_pool2d(pred, output_size=(1, 1))\n",
    "    #     print(\"triggered weird check I don't have a function for\")\n",
    "        \n",
    "    act = pred.cpu().data.numpy().reshape(pred.size(0), -1)\n",
    "    \n",
    "    mu = np.mean(act, axis=0)\n",
    "    sigma = np.cov(act, rowvar=False)\n",
    "    return mu, sigma\n",
    "    \n",
    "    "
   ],
   "id": "4cb13ae16d2f658",
   "outputs": [],
   "execution_count": 103
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T19:23:07.495971Z",
     "start_time": "2024-10-21T19:23:07.481795Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_frechet_distance(mu1, sigma1, mu2, sigma2, eps=1e-6):\n",
    "    mu1 = np.atleast_1d(mu1)\n",
    "    mu2 = np.atleast_1d(mu2)\n",
    "    \n",
    "    sigma1 = np.atleast_2d(sigma1)\n",
    "    sigma2 = np.atleast_2d(sigma2)\n",
    "    \n",
    "    assert mu1.shape == mu2.shape, \\\n",
    "        'Training and test mean vectors have different legnths'\n",
    "    assert sigma1.shape == sigma2.shape, \\\n",
    "        'Training and test covariances have different dimensions'\n",
    "    \n",
    "    diff = mu1 - mu2\n",
    "    \n",
    "    covmean, _ = linalg.sqrtm(sigma1.dot(sigma2), disp=False)\n",
    "    \n",
    "    # does something similar where it checks to see if the covmean is valid and same as the positive semi definite\n",
    "    # it adds an epsilon, though at a different point\n",
    "    if not np.isinf(covmean).all():\n",
    "        print(\"frechet distance failed; adding to diagonal of cov estimates\")\n",
    "        offset = np.eye(sigma1.shape[0]) * eps\n",
    "        \n",
    "        covmean, _ = linalg.sqrtm((sigma1 + offset).dot(sigma2 + offset), disp=False)\n",
    "        \n",
    "    if np.iscomplexobj(covmean):\n",
    "        if not np.allclose(np.diagonal(covmean).imag, 0, atol=1e-3):\n",
    "            m = np.max(np.abs(covmean.imag))\n",
    "            raise ValueError('Imaginary component {}'.format(m))\n",
    "        covmean = covmean.real\n",
    "        \n",
    "    tr_covmean = np.trace(covmean)\n",
    "    fid = (diff.dot(diff)) + np.trace(sigma1) + np.trace(sigma2) - 2 * tr_covmean\n",
    "    return fid"
   ],
   "id": "8387c7ccae11f38b",
   "outputs": [],
   "execution_count": 104
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T19:23:07.861902Z",
     "start_time": "2024-10-21T19:23:07.854430Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_fid_score(real_images, fake_images, model):\n",
    "    mu1, sigma1 = calculate_activation_statistics(real_images, model)\n",
    "    mu2, sigma2 = calculate_activation_statistics(fake_images, model)\n",
    "    \n",
    "    fid_value = calculate_frechet_distance(mu1, sigma1, mu2, sigma2)\n",
    "    return fid_value"
   ],
   "id": "e3f25031b52e29b1",
   "outputs": [],
   "execution_count": 105
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T19:23:08.180870Z",
     "start_time": "2024-10-21T19:23:08.172074Z"
    }
   },
   "cell_type": "code",
   "source": "rgb_real_images.shape",
   "id": "b6849da4f357182b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 64, 64])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 106
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T19:23:08.485396Z",
     "start_time": "2024-10-21T19:23:08.475750Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def resize_images(images):\n",
    "    return F.interpolate(images, size=(299,  299), mode='bilinear', align_corners=False)"
   ],
   "id": "855a89319157d985",
   "outputs": [],
   "execution_count": 107
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T19:23:08.971085Z",
     "start_time": "2024-10-21T19:23:08.942504Z"
    }
   },
   "cell_type": "code",
   "source": [
    "resized_rgb_real_images = resize_images(rgb_real_images)\n",
    "resized_rgb_fake_images = resize_images(rgb_fake_images)\n",
    "\n",
    "print(\"resized rgb_real_images shape: \", resized_rgb_real_images.shape)\n",
    "print(\"resized rgb_fake_images shape: \", resized_rgb_fake_images.shape)"
   ],
   "id": "308d4a29ba9b26bb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resized rgb_real_images shape:  torch.Size([32, 3, 299, 299])\n",
      "resized rgb_fake_images shape:  torch.Size([32, 3, 299, 299])\n"
     ]
    }
   ],
   "execution_count": 108
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T19:23:21.406456Z",
     "start_time": "2024-10-21T19:23:09.563723Z"
    }
   },
   "cell_type": "code",
   "source": "fid_score = calculate_fid_score(resized_rgb_real_images, resized_rgb_fake_images, inception_model)",
   "id": "cd7ed259365cb589",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frechet distance failed; adding to diagonal of cov estimates\n"
     ]
    }
   ],
   "execution_count": 109
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T19:23:21.833735Z",
     "start_time": "2024-10-21T19:23:21.819703Z"
    }
   },
   "cell_type": "code",
   "source": "fid_score",
   "id": "b6b62520245676ab",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02773356974363539"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 110
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T19:23:29.206230Z",
     "start_time": "2024-10-21T19:23:22.537566Z"
    }
   },
   "cell_type": "code",
   "source": "inception_score, is_std = calculate_inception_score(rgb_fake_images, inception_model)",
   "id": "d4db4e7892df46d2",
   "outputs": [],
   "execution_count": 111
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T19:23:29.856945Z",
     "start_time": "2024-10-21T19:23:29.831740Z"
    }
   },
   "cell_type": "code",
   "source": "inception_score",
   "id": "1aa1039d6382edfd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.1718)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 112
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T19:26:21.062284Z",
     "start_time": "2024-10-21T19:26:21.053888Z"
    }
   },
   "cell_type": "code",
   "source": [
    "np_is_score = inception_score.numpy()\n",
    "\n",
    "\n",
    "with open('dcgan_experiment_1', \"a\") as file:\n",
    "    file.write(\"dcgan_experiment 1 measurements\\n\")\n",
    "    file.write(f\"inception score {np.array2string(np_is_score)}\\n\")\n",
    "    file.write(f\"fid score {np.array2string(fid_score)}\\n\")\n"
   ],
   "id": "f7700e050ed21e7f",
   "outputs": [],
   "execution_count": 114
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T19:23:30.975460Z",
     "start_time": "2024-10-21T19:23:30.967578Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "8b9609df4de296f7",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
