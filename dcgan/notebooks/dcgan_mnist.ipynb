{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-21T15:08:34.832082Z",
     "start_time": "2024-10-21T15:08:27.240384Z"
    }
   },
   "source": [
    "import torch.nn as nn\n",
    "import torch "
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T15:08:34.860450Z",
     "start_time": "2024-10-21T15:08:34.854435Z"
    }
   },
   "cell_type": "code",
   "source": "print(torch.__version__)",
   "id": "9dc942bfe103e1c0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1+cu124\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T15:08:35.741627Z",
     "start_time": "2024-10-21T15:08:35.648292Z"
    }
   },
   "cell_type": "code",
   "source": "print(torch.cuda.is_available())",
   "id": "137b405b8ec86171",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T15:08:35.848440Z",
     "start_time": "2024-10-21T15:08:35.842034Z"
    }
   },
   "cell_type": "code",
   "source": "print(torch.version.cuda)",
   "id": "d152c5800b640b48",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.4\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T15:08:36.044775Z",
     "start_time": "2024-10-21T15:08:36.031177Z"
    }
   },
   "cell_type": "code",
   "source": "tensor_cpu = torch.randn(3, 3)",
   "id": "5629e1d8ea31d4b3",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T15:08:36.277748Z",
     "start_time": "2024-10-21T15:08:36.169292Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.cuda.empty_cache()\n",
    "tensor_gpu = tensor_cpu.to('cuda')"
   ],
   "id": "c2e24cd9d00a17f5",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T15:08:36.651418Z",
     "start_time": "2024-10-21T15:08:36.642398Z"
    }
   },
   "cell_type": "code",
   "source": "print(tensor_gpu.device)",
   "id": "54aa193243890f6a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T15:09:06.967934Z",
     "start_time": "2024-10-21T15:08:36.701248Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torchvision\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as dataloader\n",
    "from torch.utils.tensorboard import SummaryWriter\n"
   ],
   "id": "d96150f2a15503f9",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T16:14:08.932329Z",
     "start_time": "2024-10-21T16:14:08.920754Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, channels_img, features_d):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            # is the convention for Conv in pytorch N, channels, height, width?\n",
    "            nn.Conv2d(channels_img, features_d, kernel_size=4, stride=2, padding=1), # what does padding 1 correspond to?\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            nn.Conv2d(features_d, features_d * 2, kernel_size=4, stride=2, padding=1), # why features_d for filters? Why features_d * 2?\n",
    "            nn.BatchNorm2d(features_d * 2), # because GANS are known for being notoriously unstable during training -- why are GANS known for this?\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            nn.Conv2d(features_d *2, features_d * 4, kernel_size=4, stride=2, padding=1), \n",
    "            nn.BatchNorm2d(features_d * 4), \n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(features_d * 4, features_d * 8, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(features_d * 8),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            # N x features_d * 8 x 4 x 4\n",
    "            nn.Conv2d(features_d * 8, 1, kernel_size=4, stride=2, padding=0),\n",
    "            \n",
    "            # N x 1 x 1 x 1\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "    \n"
   ],
   "id": "f86d46c295864940",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T15:09:07.101607Z",
     "start_time": "2024-10-21T15:09:07.077291Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, channels_noise, channels_img, features_g):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "            \n",
    "            # N x channels_noise x 1 x 1\n",
    "            nn.ConvTranspose2d(channels_noise, features_g * 16, kernel_size=4, stride=1, padding=0), \n",
    "            nn.BatchNorm2d(features_g * 16),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            # N x features_g * 16 x 4 x 4\n",
    "            nn.ConvTranspose2d(features_g * 16, features_g * 8, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(features_g * 8),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.ConvTranspose2d(features_g * 8, features_g* 4, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(features_g * 4),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.ConvTranspose2d(features_g * 4, features_g * 2, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(features_g * 2),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.ConvTranspose2d(features_g * 2, channels_img, kernel_size=4, stride=2, padding=1),\n",
    "            \n",
    "            # N x channels_img # 64 x 64\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ],
   "id": "8c8407fe0a2f6c65",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T15:09:07.148531Z",
     "start_time": "2024-10-21T15:09:07.136792Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lr = 0.0002\n",
    "batch_size = 64\n",
    "image_size = 64 # 28 x 28 >>> 64x64\n",
    "channels_img = 1\n",
    "channels_noise = 256\n",
    "\n",
    "features_d = 16 # was set at 64 in the paper but not needed for mnist might for celebrity faces though\n",
    "features_g = 16 # was set at 64 in the paper but not needed for mnist might for celebrity faces though"
   ],
   "id": "5fbde815fb0b2678",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T15:09:07.222396Z",
     "start_time": "2024-10-21T15:09:07.208348Z"
    }
   },
   "cell_type": "code",
   "source": [
    "my_transforms = transforms.Compose([ # what does the transforms do in pytorch??\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,)),\n",
    "])"
   ],
   "id": "815cd660a175607c",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T15:09:07.417492Z",
     "start_time": "2024-10-21T15:09:07.254595Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = datasets.MNIST(root='dataset/', train=True, transform=my_transforms, download=True) # seems to download the specified dataset to my directory\n",
    "my_dataloader  = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True) # not sure what's going on thought I already imported this?\n"
   ],
   "id": "d0f0f89ecd3793b7",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T15:09:07.479309Z",
     "start_time": "2024-10-21T15:09:07.466324Z"
    }
   },
   "cell_type": "code",
   "source": "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
   "id": "dbc35f8de6c91776",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T15:09:07.657062Z",
     "start_time": "2024-10-21T15:09:07.524561Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create discriminator and generator\n",
    "\n",
    "netD = Discriminator(channels_img, features_d).to(device) #  Iguess every model has to be specified to a device? So I could run some on different gpus or my cpu? \n",
    "netG = Generator(channels_noise, channels_img, features_g).to(device)"
   ],
   "id": "305e2080cd6e3b24",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T15:09:07.707693Z",
     "start_time": "2024-10-21T15:09:07.694678Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Setup Optimizer for G and D\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(0.5, 0.999)) # why are we specifying? What is the default betas value? 0.9 and 0.999?\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(0.5, 0.999))"
   ],
   "id": "396764a0e16d0f28",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T15:09:07.782487Z",
     "start_time": "2024-10-21T15:09:07.755152Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "netD.train() # what is the difference being in training mode from otherwise in pytorch?"
   ],
   "id": "1e043c6a90181cff",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (net): Sequential(\n",
       "    (0): Conv2d(1, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.2)\n",
       "    (2): Conv2d(16, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): LeakyReLU(negative_slope=0.2)\n",
       "    (5): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): LeakyReLU(negative_slope=0.2)\n",
       "    (8): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): LeakyReLU(negative_slope=0.2)\n",
       "    (11): Conv2d(128, 1, kernel_size=(4, 4), stride=(2, 2))\n",
       "    (12): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T15:09:07.957352Z",
     "start_time": "2024-10-21T15:09:07.939629Z"
    }
   },
   "cell_type": "code",
   "source": "netG.train() # apparently the models should be in training mode by default but we're doing it explicitly",
   "id": "f6f362d3c428d92e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (net): Sequential(\n",
       "    (0): ConvTranspose2d(256, 256, kernel_size=(4, 4), stride=(1, 1))\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU()\n",
       "    (9): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (10): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): ReLU()\n",
       "    (12): ConvTranspose2d(32, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (13): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T15:09:08.125694Z",
     "start_time": "2024-10-21T15:09:08.115275Z"
    }
   },
   "cell_type": "code",
   "source": "criterion = nn.BCELoss() # binary cross entropy -- should probably ask why this specific loss function?",
   "id": "49dae3fcf107a6c3",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T15:09:08.197924Z",
     "start_time": "2024-10-21T15:09:08.188733Z"
    }
   },
   "cell_type": "code",
   "source": [
    "real_label = 1\n",
    "fake_label = 0"
   ],
   "id": "c42132f3e272208b",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T15:09:08.267363Z",
     "start_time": "2024-10-21T15:09:08.253525Z"
    }
   },
   "cell_type": "code",
   "source": "fixed_noise = torch.randn(64, channels_noise, 1, 1).to(device)",
   "id": "1cf6a8e05dcfa525",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T15:09:08.364689Z",
     "start_time": "2024-10-21T15:09:08.351199Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torchvision.transforms import ToPILImage\n",
    "import torchvision.utils as vutils"
   ],
   "id": "159eef8860ee7471",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T15:27:54.013896Z",
     "start_time": "2024-10-21T15:15:43.114588Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"starting training...\")\n",
    "num_epochs = 10\n",
    "img_idx = 0\n",
    "\n",
    "# writer_real = SummaryWriter(log_dir='runs/GAN_MNIST/log_real')\n",
    "# writer_fake = SummaryWriter(log_dir='runs/GAN_MNIST/log_fake')\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (data, targets) in enumerate(my_dataloader):\n",
    "        data = data.to(device)\n",
    "        batch_size = data.shape[0]\n",
    "        # apparently it's important that we train the Discriminator first\n",
    "        # Train Discriminator : max log (D(x)) + log(1-D(G(z)))\n",
    "        # We send in all real images first\n",
    "        netD.zero_grad()\n",
    "        label = (torch.ones(batch_size)*0.9).to(device) # apparently 0.9 helps? Would like to look at that again\n",
    "        output = netD(data).reshape(-1)\n",
    "        \n",
    "        lossD_real = criterion(output, label)\n",
    "        D_x = output.mean().item() # for evaluation purposes, could do something similar with the other models to get \n",
    "        \n",
    "        # now we send in all fake images to the discriminator\n",
    "        noise = torch.randn(batch_size, channels_noise, 1, 1).to(device)\n",
    "        fake = netG(noise)\n",
    "        label = (torch.ones(batch_size)*0.1).to(device) # would what to look at this again\n",
    "        \n",
    "        output = netD(fake.detach()).reshape(-1) # telling pytorch not to trace the gradients? Not exactly sure, does that mean we're not training the generator? \n",
    "        lossD_fake = criterion(output, label)\n",
    "        \n",
    "        lossD = lossD_real + lossD_fake\n",
    "        lossD.backward() # not sure what these are doing -- look this up\n",
    "        optimizerD.step() # need to ask about this\n",
    "        \n",
    "        # Train Generator: min log(1 - D(G(z)))\n",
    "        netG.zero_grad()\n",
    "        label = torch.ones(batch_size).to(device) # not multiplying by 0.9 here\n",
    "        output = netD(fake).reshape(-1) # we actually want to train the generator now? So we don't do detach?\n",
    "        lossG = criterion(output, label)\n",
    "        lossG.backward()\n",
    "        optimizerG.step()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f\"Epoch [{epoch}/{num_epochs}] Batch {batch_idx}/{len(my_dataloader)} \\\n",
    "             Loss D: {lossD:.4f}, Loss G: {lossG:.4f}, D(x): {D_x:.4f}\")\n",
    "            \n",
    "            with torch.no_grad(): # what is happening here?\n",
    "                fake = netG(fixed_noise)\n",
    "                \n",
    "                img_grid_real = torchvision.utils.make_grid(data[:32], normalize=True)\n",
    "                img_grid_fake = torchvision.utils.make_grid(fake[:32], normalize=True)\n",
    "                # writer_real.add_image('MNIST Real Images', img_grid_real)\n",
    "                # writer_fake.add_image('MNIST Fake Images', img_grid_fake)\n",
    "                \n",
    "                #since Tensorboard site is still being allowed, I'll provide a locall method of viewing the pictures\n",
    "                to_pil = ToPILImage()\n",
    "                \n",
    "                img_real = to_pil(img_grid_real)\n",
    "                img_real.save(f'../images/base/real/real_images_grid_{img_idx}.png')\n",
    "                \n",
    "                img_fake = to_pil(img_grid_fake)\n",
    "                img_fake.save(f'../images/base/fake/fake_images_grid_{img_idx}.png')\n",
    "                img_idx += 1\n",
    "        "
   ],
   "id": "4e8594e0da17b164",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting training...\n",
      "Epoch [0/10] Batch 0/938              Loss D: 1.3384, Loss G: 0.8055, D(x): 0.6982\n",
      "Epoch [0/10] Batch 100/938              Loss D: 0.7951, Loss G: 4.6479, D(x): 0.9146\n",
      "Epoch [0/10] Batch 200/938              Loss D: 0.7501, Loss G: 2.0221, D(x): 0.8210\n",
      "Epoch [0/10] Batch 300/938              Loss D: 0.7562, Loss G: 2.0697, D(x): 0.7506\n",
      "Epoch [0/10] Batch 400/938              Loss D: 0.7576, Loss G: 1.7986, D(x): 0.7543\n",
      "Epoch [0/10] Batch 500/938              Loss D: 0.7657, Loss G: 1.9648, D(x): 0.7800\n",
      "Epoch [0/10] Batch 600/938              Loss D: 0.9598, Loss G: 2.7237, D(x): 0.9057\n",
      "Epoch [0/10] Batch 700/938              Loss D: 1.0206, Loss G: 2.0246, D(x): 0.7973\n",
      "Epoch [0/10] Batch 800/938              Loss D: 0.9315, Loss G: 1.1806, D(x): 0.5901\n",
      "Epoch [0/10] Batch 900/938              Loss D: 1.1782, Loss G: 0.7427, D(x): 0.4421\n",
      "Epoch [1/10] Batch 0/938              Loss D: 1.1390, Loss G: 2.7669, D(x): 0.9278\n",
      "Epoch [1/10] Batch 100/938              Loss D: 1.3897, Loss G: 3.1962, D(x): 0.9696\n",
      "Epoch [1/10] Batch 200/938              Loss D: 0.8871, Loss G: 1.8499, D(x): 0.8533\n",
      "Epoch [1/10] Batch 300/938              Loss D: 0.7929, Loss G: 1.7556, D(x): 0.7200\n",
      "Epoch [1/10] Batch 400/938              Loss D: 0.8861, Loss G: 1.6044, D(x): 0.6345\n",
      "Epoch [1/10] Batch 500/938              Loss D: 0.8012, Loss G: 1.4908, D(x): 0.7843\n",
      "Epoch [1/10] Batch 600/938              Loss D: 0.9357, Loss G: 1.0878, D(x): 0.5920\n",
      "Epoch [1/10] Batch 700/938              Loss D: 0.8595, Loss G: 1.1590, D(x): 0.6491\n",
      "Epoch [1/10] Batch 800/938              Loss D: 0.9170, Loss G: 0.9061, D(x): 0.6228\n",
      "Epoch [1/10] Batch 900/938              Loss D: 0.9467, Loss G: 1.2067, D(x): 0.6246\n",
      "Epoch [2/10] Batch 0/938              Loss D: 0.8563, Loss G: 1.7281, D(x): 0.8252\n",
      "Epoch [2/10] Batch 100/938              Loss D: 0.8225, Loss G: 1.3454, D(x): 0.6780\n",
      "Epoch [2/10] Batch 200/938              Loss D: 0.9666, Loss G: 1.6963, D(x): 0.7732\n",
      "Epoch [2/10] Batch 300/938              Loss D: 0.7703, Loss G: 1.4140, D(x): 0.7626\n",
      "Epoch [2/10] Batch 400/938              Loss D: 0.8488, Loss G: 1.9960, D(x): 0.8850\n",
      "Epoch [2/10] Batch 500/938              Loss D: 0.7108, Loss G: 1.9341, D(x): 0.8146\n",
      "Epoch [2/10] Batch 600/938              Loss D: 0.8354, Loss G: 1.3830, D(x): 0.6845\n",
      "Epoch [2/10] Batch 700/938              Loss D: 0.8364, Loss G: 1.9566, D(x): 0.8533\n",
      "Epoch [2/10] Batch 800/938              Loss D: 0.8588, Loss G: 1.9463, D(x): 0.7719\n",
      "Epoch [2/10] Batch 900/938              Loss D: 1.0402, Loss G: 1.4277, D(x): 0.5201\n",
      "Epoch [3/10] Batch 0/938              Loss D: 0.7721, Loss G: 1.8121, D(x): 0.8011\n",
      "Epoch [3/10] Batch 100/938              Loss D: 0.9117, Loss G: 1.3477, D(x): 0.7076\n",
      "Epoch [3/10] Batch 200/938              Loss D: 0.7731, Loss G: 1.3927, D(x): 0.7355\n",
      "Epoch [3/10] Batch 300/938              Loss D: 0.9731, Loss G: 1.6768, D(x): 0.7640\n",
      "Epoch [3/10] Batch 400/938              Loss D: 0.8192, Loss G: 1.9811, D(x): 0.8700\n",
      "Epoch [3/10] Batch 500/938              Loss D: 0.7729, Loss G: 2.2081, D(x): 0.8103\n",
      "Epoch [3/10] Batch 600/938              Loss D: 0.8410, Loss G: 2.2135, D(x): 0.8413\n",
      "Epoch [3/10] Batch 700/938              Loss D: 0.7607, Loss G: 1.7453, D(x): 0.7427\n",
      "Epoch [3/10] Batch 800/938              Loss D: 0.7512, Loss G: 1.9700, D(x): 0.8076\n",
      "Epoch [3/10] Batch 900/938              Loss D: 0.7355, Loss G: 1.3567, D(x): 0.7848\n",
      "Epoch [4/10] Batch 0/938              Loss D: 0.8290, Loss G: 1.6692, D(x): 0.7297\n",
      "Epoch [4/10] Batch 100/938              Loss D: 0.8303, Loss G: 1.7472, D(x): 0.7597\n",
      "Epoch [4/10] Batch 200/938              Loss D: 0.8797, Loss G: 2.6019, D(x): 0.8569\n",
      "Epoch [4/10] Batch 300/938              Loss D: 0.8107, Loss G: 2.3306, D(x): 0.8355\n",
      "Epoch [4/10] Batch 400/938              Loss D: 0.7133, Loss G: 2.1156, D(x): 0.8194\n",
      "Epoch [4/10] Batch 500/938              Loss D: 0.8151, Loss G: 2.0549, D(x): 0.8569\n",
      "Epoch [4/10] Batch 600/938              Loss D: 0.7702, Loss G: 2.5879, D(x): 0.9114\n",
      "Epoch [4/10] Batch 700/938              Loss D: 0.7797, Loss G: 1.5050, D(x): 0.7862\n",
      "Epoch [4/10] Batch 800/938              Loss D: 0.7102, Loss G: 2.6240, D(x): 0.8938\n",
      "Epoch [4/10] Batch 900/938              Loss D: 0.9653, Loss G: 4.3316, D(x): 0.9404\n",
      "Epoch [5/10] Batch 0/938              Loss D: 0.7242, Loss G: 1.6791, D(x): 0.7837\n",
      "Epoch [5/10] Batch 100/938              Loss D: 0.7904, Loss G: 1.8301, D(x): 0.7585\n",
      "Epoch [5/10] Batch 200/938              Loss D: 0.8699, Loss G: 2.2712, D(x): 0.9361\n",
      "Epoch [5/10] Batch 300/938              Loss D: 0.7872, Loss G: 2.1029, D(x): 0.8865\n",
      "Epoch [5/10] Batch 400/938              Loss D: 0.7045, Loss G: 1.9825, D(x): 0.8231\n",
      "Epoch [5/10] Batch 500/938              Loss D: 0.7404, Loss G: 2.0425, D(x): 0.8399\n",
      "Epoch [5/10] Batch 600/938              Loss D: 0.7172, Loss G: 1.7665, D(x): 0.8083\n",
      "Epoch [5/10] Batch 700/938              Loss D: 0.7471, Loss G: 1.4461, D(x): 0.7654\n",
      "Epoch [5/10] Batch 800/938              Loss D: 0.8698, Loss G: 1.2852, D(x): 0.6410\n",
      "Epoch [5/10] Batch 900/938              Loss D: 0.7437, Loss G: 1.2851, D(x): 0.7537\n",
      "Epoch [6/10] Batch 0/938              Loss D: 0.7240, Loss G: 2.0650, D(x): 0.8648\n",
      "Epoch [6/10] Batch 100/938              Loss D: 0.6962, Loss G: 2.0252, D(x): 0.8332\n",
      "Epoch [6/10] Batch 200/938              Loss D: 0.7956, Loss G: 1.3562, D(x): 0.7103\n",
      "Epoch [6/10] Batch 300/938              Loss D: 0.7372, Loss G: 2.5809, D(x): 0.8559\n",
      "Epoch [6/10] Batch 400/938              Loss D: 0.7478, Loss G: 2.3457, D(x): 0.8996\n",
      "Epoch [6/10] Batch 500/938              Loss D: 0.7381, Loss G: 1.9575, D(x): 0.8125\n",
      "Epoch [6/10] Batch 600/938              Loss D: 0.6960, Loss G: 2.2020, D(x): 0.8929\n",
      "Epoch [6/10] Batch 700/938              Loss D: 0.7982, Loss G: 1.5949, D(x): 0.6966\n",
      "Epoch [6/10] Batch 800/938              Loss D: 0.7421, Loss G: 2.6317, D(x): 0.8971\n",
      "Epoch [6/10] Batch 900/938              Loss D: 0.9044, Loss G: 2.7176, D(x): 0.9423\n",
      "Epoch [7/10] Batch 0/938              Loss D: 1.9413, Loss G: 4.2487, D(x): 0.2043\n",
      "Epoch [7/10] Batch 100/938              Loss D: 0.7572, Loss G: 1.9108, D(x): 0.8665\n",
      "Epoch [7/10] Batch 200/938              Loss D: 0.9033, Loss G: 3.3041, D(x): 0.9405\n",
      "Epoch [7/10] Batch 300/938              Loss D: 0.6892, Loss G: 2.1642, D(x): 0.8494\n",
      "Epoch [7/10] Batch 400/938              Loss D: 0.7826, Loss G: 2.7117, D(x): 0.8962\n",
      "Epoch [7/10] Batch 500/938              Loss D: 0.6770, Loss G: 2.4653, D(x): 0.8804\n",
      "Epoch [7/10] Batch 600/938              Loss D: 1.4585, Loss G: 2.7362, D(x): 0.3529\n",
      "Epoch [7/10] Batch 700/938              Loss D: 0.7053, Loss G: 2.0071, D(x): 0.8098\n",
      "Epoch [7/10] Batch 800/938              Loss D: 0.6843, Loss G: 1.9564, D(x): 0.8530\n",
      "Epoch [7/10] Batch 900/938              Loss D: 0.7580, Loss G: 2.1508, D(x): 0.9190\n",
      "Epoch [8/10] Batch 0/938              Loss D: 0.7287, Loss G: 1.9164, D(x): 0.7740\n",
      "Epoch [8/10] Batch 100/938              Loss D: 0.7287, Loss G: 2.5308, D(x): 0.9085\n",
      "Epoch [8/10] Batch 200/938              Loss D: 0.7320, Loss G: 2.4360, D(x): 0.9013\n",
      "Epoch [8/10] Batch 300/938              Loss D: 0.7366, Loss G: 3.0995, D(x): 0.8632\n",
      "Epoch [8/10] Batch 400/938              Loss D: 0.7383, Loss G: 2.2832, D(x): 0.8645\n",
      "Epoch [8/10] Batch 500/938              Loss D: 0.6919, Loss G: 2.4357, D(x): 0.8739\n",
      "Epoch [8/10] Batch 600/938              Loss D: 0.7874, Loss G: 3.0294, D(x): 0.9127\n",
      "Epoch [8/10] Batch 700/938              Loss D: 0.9393, Loss G: 4.0072, D(x): 0.9768\n",
      "Epoch [8/10] Batch 800/938              Loss D: 0.6836, Loss G: 2.1067, D(x): 0.8581\n",
      "Epoch [8/10] Batch 900/938              Loss D: 5.8787, Loss G: 0.5212, D(x): 0.9981\n",
      "Epoch [9/10] Batch 0/938              Loss D: 1.1090, Loss G: 2.0251, D(x): 0.8633\n",
      "Epoch [9/10] Batch 100/938              Loss D: 0.7028, Loss G: 2.2378, D(x): 0.8475\n",
      "Epoch [9/10] Batch 200/938              Loss D: 0.6972, Loss G: 1.9173, D(x): 0.8307\n",
      "Epoch [9/10] Batch 300/938              Loss D: 0.6747, Loss G: 2.6601, D(x): 0.9101\n",
      "Epoch [9/10] Batch 400/938              Loss D: 0.6940, Loss G: 2.4452, D(x): 0.9022\n",
      "Epoch [9/10] Batch 500/938              Loss D: 0.6900, Loss G: 2.7263, D(x): 0.9072\n",
      "Epoch [9/10] Batch 600/938              Loss D: 0.6819, Loss G: 1.8714, D(x): 0.8480\n",
      "Epoch [9/10] Batch 700/938              Loss D: 0.6696, Loss G: 2.2826, D(x): 0.8902\n",
      "Epoch [9/10] Batch 800/938              Loss D: 0.6796, Loss G: 1.8306, D(x): 0.8486\n",
      "Epoch [9/10] Batch 900/938              Loss D: 0.7021, Loss G: 1.7124, D(x): 0.8240\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T15:27:54.639673Z",
     "start_time": "2024-10-21T15:27:54.025216Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torchvision.models import inception_v3\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Load pre-trained Inception v3 model\n",
    "inception_model = inception_v3(pretrained=True, transform_input=False).eval().to(device)"
   ],
   "id": "b4bbdb6199610e9",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\meddi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\meddi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Inception_V3_Weights.IMAGENET1K_V1`. You can also use `weights=Inception_V3_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T15:27:54.755025Z",
     "start_time": "2024-10-21T15:27:54.743486Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_inception_score(rgb_images, inception_model, splits=10):\n",
    "    # rgb_images = images.repeat(1, 3, 1, 1) # not necessary since I'm doing that before\n",
    "    \n",
    "    rgb_images_resized = F.interpolate(rgb_images, size=(299, 299), mode='bilinear', align_corners=False)\n",
    "    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        preds = inception_model(rgb_images_resized).softmax(dim=1)\n",
    "        \n",
    "    split_scores = []\n",
    "    for i in range(splits):\n",
    "        part = preds[i * (len(preds) // splits): ((i + 1) * len(preds) // splits), :]\n",
    "        p_y = part.mean(dim=0)\n",
    "        split_scores.append(torch.exp((part * (part.log() - p_y.log())).sum(dim=1).mean()))\n",
    "        \n",
    "    return torch.mean(torch.tensor(split_scores)), torch.std(torch.tensor(split_scores))"
   ],
   "id": "35da5b642c9af803",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T15:27:54.888695Z",
     "start_time": "2024-10-21T15:27:54.880777Z"
    }
   },
   "cell_type": "code",
   "source": "import numpy as np",
   "id": "ba2f88762984cfb0",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T15:27:55.005358Z",
     "start_time": "2024-10-21T15:27:54.999902Z"
    }
   },
   "cell_type": "code",
   "source": "from scipy import linalg",
   "id": "42ee06839d178a5e",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T15:27:55.223955Z",
     "start_time": "2024-10-21T15:27:55.132406Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_images = 32\n",
    "\n",
    "first_batch = next(iter(my_dataloader))\n",
    "\n",
    "real_images = first_batch[0]\n",
    "real_images = real_images[:num_images]\n",
    "real_images = (real_images + 1) / 2\n",
    "rgb_real_images = real_images.repeat(1, 3, 1, 1)\n",
    "rgb_real_images = rgb_real_images.to(device)\n",
    "print(\"rgb_real_images shape: \", rgb_real_images.shape)\n",
    "\n",
    "with torch.no_grad():\n",
    "    noise = torch.randn(num_images, channels_noise, 1, 1).to(device)\n",
    "    fake_images = netG(noise).to(device)\n",
    "\n",
    "    fake_images = (fake_images + 1) / 2\n",
    "    rgb_fake_images = fake_images.repeat(1, 3, 1, 1)\n",
    "    \n",
    "print(\"rgb_fake_images shape, \", rgb_fake_images.shape)\n",
    "    "
   ],
   "id": "46e50507c0b0e18d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rgb_real_images shape:  torch.Size([32, 3, 64, 64])\n",
      "rgb_fake_images shape,  torch.Size([32, 3, 64, 64])\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T15:27:55.496338Z",
     "start_time": "2024-10-21T15:27:55.485478Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_activation_statistics(images, model, dims=2048, batch_size=128):\n",
    "    model.eval()\n",
    "    act = np.empty((len(images), dims))\n",
    "    \n",
    "    batch = images.cuda()\n",
    "    \n",
    "    pred = model(batch)[0]\n",
    "    \n",
    "    # if pred.size(2) != 1 or pred.size(3) != 1:\n",
    "    #     # pred = adaptive_avg_pool2d(pred, output_size=(1, 1))\n",
    "    #     print(\"triggered weird check I don't have a function for\")\n",
    "        \n",
    "    act = pred.cpu().data.numpy().reshape(pred.size(0), -1)\n",
    "    \n",
    "    mu = np.mean(act, axis=0)\n",
    "    sigma = np.cov(act, rowvar=False)\n",
    "    return mu, sigma\n",
    "    \n",
    "    "
   ],
   "id": "4cb13ae16d2f658",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T15:27:55.776845Z",
     "start_time": "2024-10-21T15:27:55.759302Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_frechet_distance(mu1, sigma1, mu2, sigma2, eps=1e-6):\n",
    "    mu1 = np.atleast_1d(mu1)\n",
    "    mu2 = np.atleast_1d(mu2)\n",
    "    \n",
    "    sigma1 = np.atleast_2d(sigma1)\n",
    "    sigma2 = np.atleast_2d(sigma2)\n",
    "    \n",
    "    assert mu1.shape == mu2.shape, \\\n",
    "        'Training and test mean vectors have different legnths'\n",
    "    assert sigma1.shape == sigma2.shape, \\\n",
    "        'Training and test covariances have different dimensions'\n",
    "    \n",
    "    diff = mu1 - mu2\n",
    "    \n",
    "    covmean, _ = linalg.sqrtm(sigma1.dot(sigma2), disp=False)\n",
    "    \n",
    "    # does something similar where it checks to see if the covmean is valid and same as the positive semi definite\n",
    "    # it adds an epsilon, though at a different point\n",
    "    if not np.isinf(covmean).all():\n",
    "        print(\"frechet distance failed; adding to diagonal of cov estimates\")\n",
    "        offset = np.eye(sigma1.shape[0]) * eps\n",
    "        \n",
    "        covmean, _ = linalg.sqrtm((sigma1 + offset).dot(sigma2 + offset), disp=False)\n",
    "        \n",
    "    if np.iscomplexobj(covmean):\n",
    "        if not np.allclose(np.diagonal(covmean).imag, 0, atol=1e-3):\n",
    "            m = np.max(np.abs(covmean.imag))\n",
    "            raise ValueError('Imaginary component {}'.format(m))\n",
    "        covmean = covmean.real\n",
    "        \n",
    "    tr_covmean = np.trace(covmean)\n",
    "    fid = (diff.dot(diff)) + np.trace(sigma1) + np.trace(sigma2) - 2 * tr_covmean\n",
    "    return fid"
   ],
   "id": "8387c7ccae11f38b",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T15:27:56.098900Z",
     "start_time": "2024-10-21T15:27:56.084036Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_fid_score(real_images, fake_images, model):\n",
    "    mu1, sigma1 = calculate_activation_statistics(real_images, model)\n",
    "    mu2, sigma2 = calculate_activation_statistics(fake_images, model)\n",
    "    \n",
    "    fid_value = calculate_frechet_distance(mu1, sigma1, mu2, sigma2)\n",
    "    return fid_value"
   ],
   "id": "e3f25031b52e29b1",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T15:27:56.593693Z",
     "start_time": "2024-10-21T15:27:56.573759Z"
    }
   },
   "cell_type": "code",
   "source": "rgb_real_images.shape",
   "id": "b6849da4f357182b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 64, 64])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T15:27:56.992656Z",
     "start_time": "2024-10-21T15:27:56.982294Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def resize_images(images):\n",
    "    return F.interpolate(images, size=(299,  299), mode='bilinear', align_corners=False)"
   ],
   "id": "855a89319157d985",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T15:27:57.361489Z",
     "start_time": "2024-10-21T15:27:57.338661Z"
    }
   },
   "cell_type": "code",
   "source": [
    "resized_rgb_real_images = resize_images(rgb_real_images)\n",
    "resized_rgb_fake_images = resize_images(rgb_fake_images)\n",
    "\n",
    "print(\"resized rgb_real_images shape: \", resized_rgb_real_images.shape)\n",
    "print(\"resized rgb_fake_images shape: \", resized_rgb_fake_images.shape)"
   ],
   "id": "308d4a29ba9b26bb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resized rgb_real_images shape:  torch.Size([32, 3, 299, 299])\n",
      "resized rgb_fake_images shape:  torch.Size([32, 3, 299, 299])\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T15:28:07.740586Z",
     "start_time": "2024-10-21T15:27:57.747705Z"
    }
   },
   "cell_type": "code",
   "source": "fid_score = calculate_fid_score(resized_rgb_real_images, resized_rgb_fake_images, inception_model)",
   "id": "cd7ed259365cb589",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frechet distance failed; adding to diagonal of cov estimates\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T15:28:07.973365Z",
     "start_time": "2024-10-21T15:28:07.966766Z"
    }
   },
   "cell_type": "code",
   "source": "fid_score",
   "id": "b6b62520245676ab",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.003915723278531846"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T15:28:13.626165Z",
     "start_time": "2024-10-21T15:28:08.204147Z"
    }
   },
   "cell_type": "code",
   "source": "inception_score, is_std = calculate_inception_score(rgb_fake_images, inception_model)",
   "id": "d4db4e7892df46d2",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T15:28:13.859625Z",
     "start_time": "2024-10-21T15:28:13.850245Z"
    }
   },
   "cell_type": "code",
   "source": "inception_score",
   "id": "1aa1039d6382edfd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.4855)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T15:42:33.919708Z",
     "start_time": "2024-10-21T15:42:33.906139Z"
    }
   },
   "cell_type": "code",
   "source": [
    "np_is_score = inception_score.numpy()\n",
    "\n",
    "\n",
    "with open('base_dcgan', \"a\") as file:\n",
    "    file.write(\"Base_dcgan measurements\\n\")\n",
    "    file.write(f\"inception score {np.array2string(np_is_score)}\\n\")\n",
    "    file.write(f\"fid score {np.array2string(fid_score)}\\n\")\n"
   ],
   "id": "f7700e050ed21e7f",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T15:28:14.262772Z",
     "start_time": "2024-10-21T15:28:14.258303Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "8b9609df4de296f7",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
