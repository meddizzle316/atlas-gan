{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-21T20:01:36.627906Z",
     "start_time": "2024-10-21T20:01:32.253875Z"
    }
   },
   "source": [
    "import torch.nn as nn\n",
    "import torch "
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T20:01:36.636857Z",
     "start_time": "2024-10-21T20:01:36.627906Z"
    }
   },
   "cell_type": "code",
   "source": "print(torch.__version__)",
   "id": "9dc942bfe103e1c0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1+cu124\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T20:01:37.714093Z",
     "start_time": "2024-10-21T20:01:37.258637Z"
    }
   },
   "cell_type": "code",
   "source": "print(torch.cuda.is_available())",
   "id": "137b405b8ec86171",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T20:01:37.802257Z",
     "start_time": "2024-10-21T20:01:37.791066Z"
    }
   },
   "cell_type": "code",
   "source": "print(torch.version.cuda)",
   "id": "d152c5800b640b48",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.4\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T20:01:37.927716Z",
     "start_time": "2024-10-21T20:01:37.921211Z"
    }
   },
   "cell_type": "code",
   "source": "tensor_cpu = torch.randn(3, 3)",
   "id": "5629e1d8ea31d4b3",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T20:01:38.092958Z",
     "start_time": "2024-10-21T20:01:38.002179Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.cuda.empty_cache()\n",
    "tensor_gpu = tensor_cpu.to('cuda')"
   ],
   "id": "c2e24cd9d00a17f5",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T20:01:38.208084Z",
     "start_time": "2024-10-21T20:01:38.200480Z"
    }
   },
   "cell_type": "code",
   "source": "print(tensor_gpu.device)",
   "id": "54aa193243890f6a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T20:01:56.216054Z",
     "start_time": "2024-10-21T20:01:38.229272Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torchvision\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as dataloader\n",
    "from torch.utils.tensorboard import SummaryWriter\n"
   ],
   "id": "d96150f2a15503f9",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T20:01:56.740492Z",
     "start_time": "2024-10-21T20:01:56.730300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, channels_img, features_d):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            # is the convention for Conv in pytorch N, channels, height, width?\n",
    "            nn.Conv2d(channels_img, features_d, kernel_size=4, stride=2, padding=1), # what does padding 1 correspond to?\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            nn.Conv2d(features_d, features_d * 2, kernel_size=4, stride=2, padding=1), # why features_d for filters? Why features_d * 2?\n",
    "            nn.BatchNorm2d(features_d * 2), # because GANS are known for being notoriously unstable during training -- why are GANS known for this?\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            nn.Conv2d(features_d *2, features_d * 4, kernel_size=4, stride=2, padding=1), \n",
    "            nn.BatchNorm2d(features_d * 4), \n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(features_d * 4, features_d * 8, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(features_d * 8),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            # N x features_d * 8 x 4 x 4\n",
    "            nn.Conv2d(features_d * 8, 1, kernel_size=4, stride=2, padding=0),\n",
    "            \n",
    "            # N x 1 x 1 x 1\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "    \n"
   ],
   "id": "f86d46c295864940",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T20:01:56.766339Z",
     "start_time": "2024-10-21T20:01:56.758952Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, channels_noise, channels_img, features_g):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "            \n",
    "            # N x channels_noise x 1 x 1\n",
    "            nn.ConvTranspose2d(channels_noise, features_g * 16, kernel_size=4, stride=1, padding=0), \n",
    "            nn.BatchNorm2d(features_g * 16),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            # N x features_g * 16 x 4 x 4\n",
    "            nn.ConvTranspose2d(features_g * 16, features_g * 8, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(features_g * 8),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.ConvTranspose2d(features_g * 8, features_g* 4, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(features_g * 4),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.ConvTranspose2d(features_g * 4, features_g * 2, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(features_g * 2),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.ConvTranspose2d(features_g * 2, channels_img, kernel_size=4, stride=2, padding=1),\n",
    "            \n",
    "            # N x channels_img # 64 x 64\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ],
   "id": "8c8407fe0a2f6c65",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T20:01:56.796340Z",
     "start_time": "2024-10-21T20:01:56.792257Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lr = 0.0002\n",
    "batch_size = 64\n",
    "image_size = 64 # 28 x 28 >>> 64x64\n",
    "channels_img = 1\n",
    "channels_noise = 256\n",
    "\n",
    "features_d = 16 # was set at 64 in the paper but not needed for mnist might for celebrity faces though\n",
    "features_g = 16 # was set at 64 in the paper but not needed for mnist might for celebrity faces though"
   ],
   "id": "5fbde815fb0b2678",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T20:01:56.819392Z",
     "start_time": "2024-10-21T20:01:56.811810Z"
    }
   },
   "cell_type": "code",
   "source": [
    "my_transforms = transforms.Compose([ # what does the transforms do in pytorch??\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,)),\n",
    "])"
   ],
   "id": "815cd660a175607c",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T20:01:56.916728Z",
     "start_time": "2024-10-21T20:01:56.832739Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = datasets.MNIST(root='dataset/', train=True, transform=my_transforms, download=True) # seems to download the specified dataset to my directory\n",
    "my_dataloader  = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True) # not sure what's going on thought I already imported this?\n"
   ],
   "id": "d0f0f89ecd3793b7",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T20:01:56.939325Z",
     "start_time": "2024-10-21T20:01:56.932788Z"
    }
   },
   "cell_type": "code",
   "source": "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
   "id": "dbc35f8de6c91776",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T20:01:57.037043Z",
     "start_time": "2024-10-21T20:01:56.967930Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create discriminator and generator\n",
    "\n",
    "netD = Discriminator(channels_img, features_d).to(device) #  Iguess every model has to be specified to a device? So I could run some on different gpus or my cpu? \n",
    "netG = Generator(channels_noise, channels_img, features_g).to(device)"
   ],
   "id": "305e2080cd6e3b24",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T20:01:57.058547Z",
     "start_time": "2024-10-21T20:01:57.050448Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Setup Optimizer for G and D\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(0.9, 0.999)) # why are we specifying? What is the default betas value? 0.9 and 0.999?\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(0.9, 0.999))"
   ],
   "id": "396764a0e16d0f28",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T20:01:57.099739Z",
     "start_time": "2024-10-21T20:01:57.086544Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "netD.train() # what is the difference being in training mode from otherwise in pytorch?"
   ],
   "id": "1e043c6a90181cff",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (net): Sequential(\n",
       "    (0): Conv2d(1, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.2)\n",
       "    (2): Conv2d(16, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): LeakyReLU(negative_slope=0.2)\n",
       "    (5): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): LeakyReLU(negative_slope=0.2)\n",
       "    (8): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): LeakyReLU(negative_slope=0.2)\n",
       "    (11): Conv2d(128, 1, kernel_size=(4, 4), stride=(2, 2))\n",
       "    (12): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T20:01:57.155676Z",
     "start_time": "2024-10-21T20:01:57.143401Z"
    }
   },
   "cell_type": "code",
   "source": "netG.train() # apparently the models should be in training mode by default but we're doing it explicitly",
   "id": "f6f362d3c428d92e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (net): Sequential(\n",
       "    (0): ConvTranspose2d(256, 256, kernel_size=(4, 4), stride=(1, 1))\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU()\n",
       "    (9): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (10): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): ReLU()\n",
       "    (12): ConvTranspose2d(32, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (13): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T20:01:57.214755Z",
     "start_time": "2024-10-21T20:01:57.208009Z"
    }
   },
   "cell_type": "code",
   "source": "criterion = nn.BCELoss() # binary cross entropy -- should probably ask why this specific loss function?",
   "id": "49dae3fcf107a6c3",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T20:01:57.239558Z",
     "start_time": "2024-10-21T20:01:57.232620Z"
    }
   },
   "cell_type": "code",
   "source": [
    "real_label = 1\n",
    "fake_label = 0"
   ],
   "id": "c42132f3e272208b",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T20:01:57.297657Z",
     "start_time": "2024-10-21T20:01:57.289626Z"
    }
   },
   "cell_type": "code",
   "source": "fixed_noise = torch.randn(64, channels_noise, 1, 1).to(device)",
   "id": "1cf6a8e05dcfa525",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T20:01:57.370356Z",
     "start_time": "2024-10-21T20:01:57.362014Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torchvision.transforms import ToPILImage\n",
    "import torchvision.utils as vutils"
   ],
   "id": "159eef8860ee7471",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T20:11:36.766946Z",
     "start_time": "2024-10-21T20:01:57.421127Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"starting training...\")\n",
    "num_epochs = 10\n",
    "img_idx = 0\n",
    "\n",
    "# writer_real = SummaryWriter(log_dir='runs/GAN_MNIST/log_real')\n",
    "# writer_fake = SummaryWriter(log_dir='runs/GAN_MNIST/log_fake')\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (data, targets) in enumerate(my_dataloader):\n",
    "        data = data.to(device)\n",
    "        batch_size = data.shape[0]\n",
    "        # apparently it's important that we train the Discriminator first\n",
    "        # Train Discriminator : max log (D(x)) + log(1-D(G(z)))\n",
    "        # We send in all real images first\n",
    "        netD.zero_grad()\n",
    "        label = (torch.ones(batch_size)*0.9).to(device) # apparently 0.9 helps? Would like to look at that again\n",
    "        output = netD(data).reshape(-1)\n",
    "        \n",
    "        lossD_real = criterion(output, label)\n",
    "        D_x = output.mean().item() # for evaluation purposes, could do something similar with the other models to get \n",
    "        \n",
    "        # now we send in all fake images to the discriminator\n",
    "        noise = torch.randn(batch_size, channels_noise, 1, 1).to(device)\n",
    "        fake = netG(noise)\n",
    "        label = (torch.ones(batch_size)*0.1).to(device) # would what to look at this again\n",
    "        \n",
    "        output = netD(fake.detach()).reshape(-1) # telling pytorch not to trace the gradients? Not exactly sure, does that mean we're not training the generator? \n",
    "        lossD_fake = criterion(output, label)\n",
    "        \n",
    "        lossD = lossD_real + lossD_fake\n",
    "        lossD.backward() # not sure what these are doing -- look this up\n",
    "        optimizerD.step() # need to ask about this\n",
    "        \n",
    "        # Train Generator: min log(1 - D(G(z)))\n",
    "        netG.zero_grad()\n",
    "        label = torch.ones(batch_size).to(device) # not multiplying by 0.9 here\n",
    "        output = netD(fake).reshape(-1) # we actually want to train the generator now? So we don't do detach?\n",
    "        lossG = criterion(output, label)\n",
    "        lossG.backward()\n",
    "        optimizerG.step()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f\"Epoch [{epoch}/{num_epochs}] Batch {batch_idx}/{len(my_dataloader)} \\\n",
    "             Loss D: {lossD:.4f}, Loss G: {lossG:.4f}, D(x): {D_x:.4f}\")\n",
    "            \n",
    "            with torch.no_grad(): # what is happening here?\n",
    "                fake = netG(fixed_noise)\n",
    "                \n",
    "                img_grid_real = torchvision.utils.make_grid(data[:32], normalize=True)\n",
    "                img_grid_fake = torchvision.utils.make_grid(fake[:32], normalize=True)\n",
    "                # writer_real.add_image('MNIST Real Images', img_grid_real)\n",
    "                # writer_fake.add_image('MNIST Fake Images', img_grid_fake)\n",
    "                \n",
    "                #since Tensorboard site is still being allowed, I'll provide a locall method of viewing the pictures\n",
    "                to_pil = ToPILImage()\n",
    "                \n",
    "                img_real = to_pil(img_grid_real)\n",
    "                img_real.save(f'../images/experiment2/real/real_images_grid_{img_idx}.png')\n",
    "                \n",
    "                img_fake = to_pil(img_grid_fake)\n",
    "                img_fake.save(f'../images/experiment2/fake/fake_images_grid_{img_idx}.png')\n",
    "                img_idx += 1\n",
    "        "
   ],
   "id": "4e8594e0da17b164",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting training...\n",
      "Epoch [0/10] Batch 0/938              Loss D: 1.4748, Loss G: 0.7953, D(x): 0.4957\n",
      "Epoch [0/10] Batch 100/938              Loss D: 0.6721, Loss G: 2.7873, D(x): 0.8752\n",
      "Epoch [0/10] Batch 200/938              Loss D: 0.6613, Loss G: 2.7442, D(x): 0.8703\n",
      "Epoch [0/10] Batch 300/938              Loss D: 0.6595, Loss G: 2.5166, D(x): 0.8686\n",
      "Epoch [0/10] Batch 400/938              Loss D: 0.6578, Loss G: 2.5042, D(x): 0.9097\n",
      "Epoch [0/10] Batch 500/938              Loss D: 0.6572, Loss G: 2.4167, D(x): 0.8921\n",
      "Epoch [0/10] Batch 600/938              Loss D: 0.7210, Loss G: 2.6812, D(x): 0.9119\n",
      "Epoch [0/10] Batch 700/938              Loss D: 0.6554, Loss G: 2.3210, D(x): 0.8984\n",
      "Epoch [0/10] Batch 800/938              Loss D: 0.6599, Loss G: 2.3524, D(x): 0.9051\n",
      "Epoch [0/10] Batch 900/938              Loss D: 0.7482, Loss G: 2.3859, D(x): 0.9380\n",
      "Epoch [1/10] Batch 0/938              Loss D: 0.6626, Loss G: 2.3741, D(x): 0.9063\n",
      "Epoch [1/10] Batch 100/938              Loss D: 0.7165, Loss G: 2.3697, D(x): 0.9167\n",
      "Epoch [1/10] Batch 200/938              Loss D: 0.6739, Loss G: 2.7767, D(x): 0.8962\n",
      "Epoch [1/10] Batch 300/938              Loss D: 0.6751, Loss G: 2.2174, D(x): 0.8575\n",
      "Epoch [1/10] Batch 400/938              Loss D: 0.6757, Loss G: 2.0461, D(x): 0.8999\n",
      "Epoch [1/10] Batch 500/938              Loss D: 0.6712, Loss G: 2.0398, D(x): 0.8687\n",
      "Epoch [1/10] Batch 600/938              Loss D: 0.6792, Loss G: 2.2711, D(x): 0.8572\n",
      "Epoch [1/10] Batch 700/938              Loss D: 0.6970, Loss G: 1.6656, D(x): 0.8993\n",
      "Epoch [1/10] Batch 800/938              Loss D: 0.6877, Loss G: 2.5094, D(x): 0.9419\n",
      "Epoch [1/10] Batch 900/938              Loss D: 0.6600, Loss G: 2.5259, D(x): 0.8715\n",
      "Epoch [2/10] Batch 0/938              Loss D: 0.6787, Loss G: 3.7710, D(x): 0.8684\n",
      "Epoch [2/10] Batch 100/938              Loss D: 0.6652, Loss G: 2.4487, D(x): 0.8881\n",
      "Epoch [2/10] Batch 200/938              Loss D: 0.7047, Loss G: 2.2993, D(x): 0.8150\n",
      "Epoch [2/10] Batch 300/938              Loss D: 0.7709, Loss G: 2.1710, D(x): 0.9605\n",
      "Epoch [2/10] Batch 400/938              Loss D: 0.6865, Loss G: 2.0037, D(x): 0.8676\n",
      "Epoch [2/10] Batch 500/938              Loss D: 0.6790, Loss G: 2.4767, D(x): 0.8610\n",
      "Epoch [2/10] Batch 600/938              Loss D: 0.6782, Loss G: 2.1666, D(x): 0.8586\n",
      "Epoch [2/10] Batch 700/938              Loss D: 0.7045, Loss G: 1.8734, D(x): 0.9215\n",
      "Epoch [2/10] Batch 800/938              Loss D: 0.9378, Loss G: 2.0538, D(x): 0.6216\n",
      "Epoch [2/10] Batch 900/938              Loss D: 1.0527, Loss G: 1.4080, D(x): 0.5364\n",
      "Epoch [3/10] Batch 0/938              Loss D: 0.7043, Loss G: 1.7466, D(x): 0.8670\n",
      "Epoch [3/10] Batch 100/938              Loss D: 0.8051, Loss G: 2.8163, D(x): 0.8255\n",
      "Epoch [3/10] Batch 200/938              Loss D: 0.7792, Loss G: 1.7180, D(x): 0.8814\n",
      "Epoch [3/10] Batch 300/938              Loss D: 0.7236, Loss G: 2.1370, D(x): 0.8627\n",
      "Epoch [3/10] Batch 400/938              Loss D: 0.9075, Loss G: 2.0740, D(x): 0.9648\n",
      "Epoch [3/10] Batch 500/938              Loss D: 0.7606, Loss G: 1.8643, D(x): 0.8114\n",
      "Epoch [3/10] Batch 600/938              Loss D: 0.9355, Loss G: 1.4061, D(x): 0.5981\n",
      "Epoch [3/10] Batch 700/938              Loss D: 0.7492, Loss G: 1.8188, D(x): 0.7689\n",
      "Epoch [3/10] Batch 800/938              Loss D: 0.7202, Loss G: 2.4218, D(x): 0.8153\n",
      "Epoch [3/10] Batch 900/938              Loss D: 0.7101, Loss G: 2.1721, D(x): 0.8755\n",
      "Epoch [4/10] Batch 0/938              Loss D: 0.7049, Loss G: 2.0518, D(x): 0.8232\n",
      "Epoch [4/10] Batch 100/938              Loss D: 0.8239, Loss G: 1.9857, D(x): 0.9434\n",
      "Epoch [4/10] Batch 200/938              Loss D: 0.7394, Loss G: 2.2494, D(x): 0.9150\n",
      "Epoch [4/10] Batch 300/938              Loss D: 0.7472, Loss G: 2.7720, D(x): 0.7717\n",
      "Epoch [4/10] Batch 400/938              Loss D: 0.7643, Loss G: 2.3271, D(x): 0.7852\n",
      "Epoch [4/10] Batch 500/938              Loss D: 0.7377, Loss G: 2.1758, D(x): 0.8728\n",
      "Epoch [4/10] Batch 600/938              Loss D: 0.7226, Loss G: 2.0018, D(x): 0.8798\n",
      "Epoch [4/10] Batch 700/938              Loss D: 0.9008, Loss G: 1.3514, D(x): 0.8718\n",
      "Epoch [4/10] Batch 800/938              Loss D: 0.7308, Loss G: 1.8261, D(x): 0.8417\n",
      "Epoch [4/10] Batch 900/938              Loss D: 0.7110, Loss G: 2.8012, D(x): 0.8502\n",
      "Epoch [5/10] Batch 0/938              Loss D: 0.7467, Loss G: 2.0038, D(x): 0.8336\n",
      "Epoch [5/10] Batch 100/938              Loss D: 0.7191, Loss G: 2.4197, D(x): 0.8769\n",
      "Epoch [5/10] Batch 200/938              Loss D: 0.7319, Loss G: 1.9270, D(x): 0.8806\n",
      "Epoch [5/10] Batch 300/938              Loss D: 0.7632, Loss G: 1.4789, D(x): 0.7580\n",
      "Epoch [5/10] Batch 400/938              Loss D: 0.7815, Loss G: 1.8455, D(x): 0.8869\n",
      "Epoch [5/10] Batch 500/938              Loss D: 0.6879, Loss G: 2.1797, D(x): 0.8434\n",
      "Epoch [5/10] Batch 600/938              Loss D: 0.8730, Loss G: 2.4518, D(x): 0.6377\n",
      "Epoch [5/10] Batch 700/938              Loss D: 0.8130, Loss G: 1.7355, D(x): 0.8920\n",
      "Epoch [5/10] Batch 800/938              Loss D: 0.7541, Loss G: 2.1772, D(x): 0.8959\n",
      "Epoch [5/10] Batch 900/938              Loss D: 0.7617, Loss G: 2.4031, D(x): 0.7373\n",
      "Epoch [6/10] Batch 0/938              Loss D: 0.7170, Loss G: 2.5038, D(x): 0.8398\n",
      "Epoch [6/10] Batch 100/938              Loss D: 0.7191, Loss G: 2.3026, D(x): 0.8008\n",
      "Epoch [6/10] Batch 200/938              Loss D: 0.7197, Loss G: 1.7989, D(x): 0.7958\n",
      "Epoch [6/10] Batch 300/938              Loss D: 0.8441, Loss G: 2.5153, D(x): 0.6745\n",
      "Epoch [6/10] Batch 400/938              Loss D: 0.7731, Loss G: 1.6838, D(x): 0.7667\n",
      "Epoch [6/10] Batch 500/938              Loss D: 0.7210, Loss G: 1.8237, D(x): 0.7987\n",
      "Epoch [6/10] Batch 600/938              Loss D: 0.7638, Loss G: 1.8856, D(x): 0.8848\n",
      "Epoch [6/10] Batch 700/938              Loss D: 0.7446, Loss G: 1.6101, D(x): 0.9075\n",
      "Epoch [6/10] Batch 800/938              Loss D: 0.7017, Loss G: 2.4468, D(x): 0.8867\n",
      "Epoch [6/10] Batch 900/938              Loss D: 0.7177, Loss G: 2.6755, D(x): 0.7934\n",
      "Epoch [7/10] Batch 0/938              Loss D: 0.8004, Loss G: 1.4833, D(x): 0.9113\n",
      "Epoch [7/10] Batch 100/938              Loss D: 0.7349, Loss G: 2.1908, D(x): 0.8758\n",
      "Epoch [7/10] Batch 200/938              Loss D: 0.7183, Loss G: 2.2675, D(x): 0.8620\n",
      "Epoch [7/10] Batch 300/938              Loss D: 0.6956, Loss G: 2.1743, D(x): 0.8729\n",
      "Epoch [7/10] Batch 400/938              Loss D: 0.7678, Loss G: 1.1517, D(x): 0.7883\n",
      "Epoch [7/10] Batch 500/938              Loss D: 0.8222, Loss G: 1.5775, D(x): 0.8715\n",
      "Epoch [7/10] Batch 600/938              Loss D: 0.7174, Loss G: 2.6455, D(x): 0.8714\n",
      "Epoch [7/10] Batch 700/938              Loss D: 0.7520, Loss G: 2.1570, D(x): 0.9376\n",
      "Epoch [7/10] Batch 800/938              Loss D: 0.6754, Loss G: 2.1878, D(x): 0.8935\n",
      "Epoch [7/10] Batch 900/938              Loss D: 0.7676, Loss G: 2.1366, D(x): 0.9322\n",
      "Epoch [8/10] Batch 0/938              Loss D: 0.7097, Loss G: 1.4684, D(x): 0.8441\n",
      "Epoch [8/10] Batch 100/938              Loss D: 0.7136, Loss G: 2.8624, D(x): 0.8115\n",
      "Epoch [8/10] Batch 200/938              Loss D: 0.6833, Loss G: 2.3455, D(x): 0.8819\n",
      "Epoch [8/10] Batch 300/938              Loss D: 0.7201, Loss G: 2.5445, D(x): 0.8075\n",
      "Epoch [8/10] Batch 400/938              Loss D: 0.6936, Loss G: 2.8302, D(x): 0.8637\n",
      "Epoch [8/10] Batch 500/938              Loss D: 0.7111, Loss G: 1.9937, D(x): 0.8254\n",
      "Epoch [8/10] Batch 600/938              Loss D: 0.6822, Loss G: 2.5268, D(x): 0.8862\n",
      "Epoch [8/10] Batch 700/938              Loss D: 0.7084, Loss G: 1.6994, D(x): 0.9080\n",
      "Epoch [8/10] Batch 800/938              Loss D: 0.7973, Loss G: 2.2716, D(x): 0.9468\n",
      "Epoch [8/10] Batch 900/938              Loss D: 0.6953, Loss G: 1.4967, D(x): 0.8421\n",
      "Epoch [9/10] Batch 0/938              Loss D: 0.7186, Loss G: 2.4750, D(x): 0.8027\n",
      "Epoch [9/10] Batch 100/938              Loss D: 0.7746, Loss G: 2.1627, D(x): 0.7212\n",
      "Epoch [9/10] Batch 200/938              Loss D: 0.7104, Loss G: 2.0832, D(x): 0.8824\n",
      "Epoch [9/10] Batch 300/938              Loss D: 0.7149, Loss G: 2.1503, D(x): 0.8409\n",
      "Epoch [9/10] Batch 400/938              Loss D: 0.6990, Loss G: 1.9146, D(x): 0.8255\n",
      "Epoch [9/10] Batch 500/938              Loss D: 0.7480, Loss G: 1.8589, D(x): 0.7511\n",
      "Epoch [9/10] Batch 600/938              Loss D: 0.8089, Loss G: 1.3179, D(x): 0.9522\n",
      "Epoch [9/10] Batch 700/938              Loss D: 0.7052, Loss G: 2.0437, D(x): 0.8234\n",
      "Epoch [9/10] Batch 800/938              Loss D: 0.7870, Loss G: 1.8228, D(x): 0.9434\n",
      "Epoch [9/10] Batch 900/938              Loss D: 0.7158, Loss G: 2.0542, D(x): 0.9076\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T20:11:37.215659Z",
     "start_time": "2024-10-21T20:11:36.769448Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torchvision.models import inception_v3\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Load pre-trained Inception v3 model\n",
    "inception_model = inception_v3(pretrained=True, transform_input=False).eval().to(device)"
   ],
   "id": "b4bbdb6199610e9",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\meddi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\meddi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Inception_V3_Weights.IMAGENET1K_V1`. You can also use `weights=Inception_V3_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T20:11:37.336985Z",
     "start_time": "2024-10-21T20:11:37.329264Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_inception_score(rgb_images, inception_model, splits=10):\n",
    "    # rgb_images = images.repeat(1, 3, 1, 1) # not necessary since I'm doing that before\n",
    "    \n",
    "    rgb_images_resized = F.interpolate(rgb_images, size=(299, 299), mode='bilinear', align_corners=False)\n",
    "    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        preds = inception_model(rgb_images_resized).softmax(dim=1)\n",
    "        \n",
    "    split_scores = []\n",
    "    for i in range(splits):\n",
    "        part = preds[i * (len(preds) // splits): ((i + 1) * len(preds) // splits), :]\n",
    "        p_y = part.mean(dim=0)\n",
    "        split_scores.append(torch.exp((part * (part.log() - p_y.log())).sum(dim=1).mean()))\n",
    "        \n",
    "    return torch.mean(torch.tensor(split_scores)), torch.std(torch.tensor(split_scores))"
   ],
   "id": "35da5b642c9af803",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T20:11:37.441291Z",
     "start_time": "2024-10-21T20:11:37.434934Z"
    }
   },
   "cell_type": "code",
   "source": "import numpy as np",
   "id": "ba2f88762984cfb0",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T20:11:37.554088Z",
     "start_time": "2024-10-21T20:11:37.546241Z"
    }
   },
   "cell_type": "code",
   "source": "from scipy import linalg",
   "id": "42ee06839d178a5e",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T20:11:37.732058Z",
     "start_time": "2024-10-21T20:11:37.680092Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_images = 32\n",
    "\n",
    "first_batch = next(iter(my_dataloader))\n",
    "\n",
    "real_images = first_batch[0]\n",
    "real_images = real_images[:num_images]\n",
    "real_images = (real_images + 1) / 2\n",
    "rgb_real_images = real_images.repeat(1, 3, 1, 1)\n",
    "rgb_real_images = rgb_real_images.to(device)\n",
    "print(\"rgb_real_images shape: \", rgb_real_images.shape)\n",
    "\n",
    "with torch.no_grad():\n",
    "    noise = torch.randn(num_images, channels_noise, 1, 1).to(device)\n",
    "    fake_images = netG(noise).to(device)\n",
    "\n",
    "    fake_images = (fake_images + 1) / 2\n",
    "    rgb_fake_images = fake_images.repeat(1, 3, 1, 1)\n",
    "    \n",
    "print(\"rgb_fake_images shape, \", rgb_fake_images.shape)\n",
    "    "
   ],
   "id": "46e50507c0b0e18d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rgb_real_images shape:  torch.Size([32, 3, 64, 64])\n",
      "rgb_fake_images shape,  torch.Size([32, 3, 64, 64])\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T20:11:37.989919Z",
     "start_time": "2024-10-21T20:11:37.979055Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_activation_statistics(images, model, dims=2048, batch_size=128):\n",
    "    model.eval()\n",
    "    act = np.empty((len(images), dims))\n",
    "    \n",
    "    batch = images.cuda()\n",
    "    \n",
    "    pred = model(batch)[0]\n",
    "    \n",
    "    # if pred.size(2) != 1 or pred.size(3) != 1:\n",
    "    #     # pred = adaptive_avg_pool2d(pred, output_size=(1, 1))\n",
    "    #     print(\"triggered weird check I don't have a function for\")\n",
    "        \n",
    "    act = pred.cpu().data.numpy().reshape(pred.size(0), -1)\n",
    "    \n",
    "    mu = np.mean(act, axis=0)\n",
    "    sigma = np.cov(act, rowvar=False)\n",
    "    return mu, sigma\n",
    "    \n",
    "    "
   ],
   "id": "4cb13ae16d2f658",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T20:11:38.272911Z",
     "start_time": "2024-10-21T20:11:38.260324Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_frechet_distance(mu1, sigma1, mu2, sigma2, eps=1e-6):\n",
    "    mu1 = np.atleast_1d(mu1)\n",
    "    mu2 = np.atleast_1d(mu2)\n",
    "    \n",
    "    sigma1 = np.atleast_2d(sigma1)\n",
    "    sigma2 = np.atleast_2d(sigma2)\n",
    "    \n",
    "    assert mu1.shape == mu2.shape, \\\n",
    "        'Training and test mean vectors have different legnths'\n",
    "    assert sigma1.shape == sigma2.shape, \\\n",
    "        'Training and test covariances have different dimensions'\n",
    "    \n",
    "    diff = mu1 - mu2\n",
    "    \n",
    "    covmean, _ = linalg.sqrtm(sigma1.dot(sigma2), disp=False)\n",
    "    \n",
    "    # does something similar where it checks to see if the covmean is valid and same as the positive semi definite\n",
    "    # it adds an epsilon, though at a different point\n",
    "    if not np.isinf(covmean).all():\n",
    "        print(\"frechet distance failed; adding to diagonal of cov estimates\")\n",
    "        offset = np.eye(sigma1.shape[0]) * eps\n",
    "        \n",
    "        covmean, _ = linalg.sqrtm((sigma1 + offset).dot(sigma2 + offset), disp=False)\n",
    "        \n",
    "    if np.iscomplexobj(covmean):\n",
    "        if not np.allclose(np.diagonal(covmean).imag, 0, atol=1e-3):\n",
    "            m = np.max(np.abs(covmean.imag))\n",
    "            raise ValueError('Imaginary component {}'.format(m))\n",
    "        covmean = covmean.real\n",
    "        \n",
    "    tr_covmean = np.trace(covmean)\n",
    "    fid = (diff.dot(diff)) + np.trace(sigma1) + np.trace(sigma2) - 2 * tr_covmean\n",
    "    return fid"
   ],
   "id": "8387c7ccae11f38b",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T20:11:38.517625Z",
     "start_time": "2024-10-21T20:11:38.507567Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_fid_score(real_images, fake_images, model):\n",
    "    mu1, sigma1 = calculate_activation_statistics(real_images, model)\n",
    "    mu2, sigma2 = calculate_activation_statistics(fake_images, model)\n",
    "    \n",
    "    fid_value = calculate_frechet_distance(mu1, sigma1, mu2, sigma2)\n",
    "    return fid_value"
   ],
   "id": "e3f25031b52e29b1",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T20:11:38.796467Z",
     "start_time": "2024-10-21T20:11:38.784510Z"
    }
   },
   "cell_type": "code",
   "source": "rgb_real_images.shape",
   "id": "b6849da4f357182b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 64, 64])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T20:11:39.067295Z",
     "start_time": "2024-10-21T20:11:39.058892Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def resize_images(images):\n",
    "    return F.interpolate(images, size=(299,  299), mode='bilinear', align_corners=False)"
   ],
   "id": "855a89319157d985",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T20:11:39.473227Z",
     "start_time": "2024-10-21T20:11:39.457367Z"
    }
   },
   "cell_type": "code",
   "source": [
    "resized_rgb_real_images = resize_images(rgb_real_images)\n",
    "resized_rgb_fake_images = resize_images(rgb_fake_images)\n",
    "\n",
    "print(\"resized rgb_real_images shape: \", resized_rgb_real_images.shape)\n",
    "print(\"resized rgb_fake_images shape: \", resized_rgb_fake_images.shape)"
   ],
   "id": "308d4a29ba9b26bb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resized rgb_real_images shape:  torch.Size([32, 3, 299, 299])\n",
      "resized rgb_fake_images shape:  torch.Size([32, 3, 299, 299])\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T20:11:49.658363Z",
     "start_time": "2024-10-21T20:11:39.918812Z"
    }
   },
   "cell_type": "code",
   "source": "fid_score = calculate_fid_score(resized_rgb_real_images, resized_rgb_fake_images, inception_model)",
   "id": "cd7ed259365cb589",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frechet distance failed; adding to diagonal of cov estimates\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T20:11:49.915157Z",
     "start_time": "2024-10-21T20:11:49.908315Z"
    }
   },
   "cell_type": "code",
   "source": "fid_score",
   "id": "b6b62520245676ab",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0007128128915363519"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T20:11:55.526367Z",
     "start_time": "2024-10-21T20:11:50.132132Z"
    }
   },
   "cell_type": "code",
   "source": "inception_score, is_std = calculate_inception_score(rgb_fake_images, inception_model)",
   "id": "d4db4e7892df46d2",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T20:11:55.766384Z",
     "start_time": "2024-10-21T20:11:55.754840Z"
    }
   },
   "cell_type": "code",
   "source": "inception_score",
   "id": "1aa1039d6382edfd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.7026)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T20:11:56.021Z",
     "start_time": "2024-10-21T20:11:56.013940Z"
    }
   },
   "cell_type": "code",
   "source": [
    "np_is_score = inception_score.numpy()\n",
    "\n",
    "\n",
    "with open('dcgan_experiment_2', \"a\") as file:\n",
    "    file.write(\"dcgan_experiment_2 measurements\\n\")\n",
    "    file.write(f\"inception score {np.array2string(np_is_score)}\\n\")\n",
    "    file.write(f\"fid score {np.array2string(fid_score)}\\n\")\n"
   ],
   "id": "f7700e050ed21e7f",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T20:11:56.293867Z",
     "start_time": "2024-10-21T20:11:56.289220Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "8b9609df4de296f7",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
