Observations:

Training Time: Given the lack of time, I had to buy some GPU units from Google Colab,
which significantly reduced the training time (as I was accessing higher end GPUs, their A100).
This resulted in a per epoch time decrease of about 66% (the epochs previously took about 45 minutes and this
loop they only took about  15 minutes)

Architecture changes: I made a few changes, the main one being I added an additional Conv2d and ConvTranspose2d to the
Discriminator and Generator models respectively. To do this, I also resized the images to 128 x 128 instead of 64 x 64. I
also changed the beta values to 0.0, 0.9 for the Adam optimizers for the Generator model (it was already like that for the
Discriminator model)

Loss: The thing that was interesting to me about this loop was how high the generator loss was, in addition
to it's very obvious instability during the training process. Given that I use the same beta hyperparameters in exp #2,
my guess is that it has to do with the additional layer to each model or to the resizing of the images to fit that new architecture.
The discriminator loss, while being fairly unstable, still managed to decrease over the 5 epochs.



  4%|▍         | 100/2544 [00:34<13:31,  3.01it/s]Epoch [0/5] Batch 100/2544                 loss D: -460.2155, loss G 323.5064
  8%|▊         | 200/2544 [01:08<12:53,  3.03it/s]Epoch [0/5] Batch 200/2544                 loss D: -420.2655, loss G 482.4665
 12%|█▏        | 300/2544 [01:42<12:17,  3.04it/s]Epoch [0/5] Batch 300/2544                 loss D: -306.3902, loss G 426.0183
 16%|█▌        | 400/2544 [02:16<11:48,  3.02it/s]Epoch [0/5] Batch 400/2544                 loss D: -178.2318, loss G 397.3712
 20%|█▉        | 500/2544 [02:50<11:14,  3.03it/s]Epoch [0/5] Batch 500/2544                 loss D: -135.7382, loss G 407.1526
 24%|██▎       | 600/2544 [03:24<10:40,  3.03it/s]Epoch [0/5] Batch 600/2544                 loss D: -83.6656, loss G 326.6003
 28%|██▊       | 700/2544 [03:58<10:07,  3.03it/s]Epoch [0/5] Batch 700/2544                 loss D: -75.4858, loss G 305.0259
 31%|███▏      | 800/2544 [04:32<09:32,  3.04it/s]Epoch [0/5] Batch 800/2544                 loss D: -78.1376, loss G 298.1005
 35%|███▌      | 900/2544 [05:06<09:02,  3.03it/s]Epoch [0/5] Batch 900/2544                 loss D: -60.9223, loss G 293.2079
 39%|███▉      | 1000/2544 [05:40<08:30,  3.03it/s]Epoch [0/5] Batch 1000/2544                 loss D: -71.5527, loss G 285.4649
 43%|████▎     | 1100/2544 [06:14<07:53,  3.05it/s]Epoch [0/5] Batch 1100/2544                 loss D: -63.7567, loss G 258.6405
 47%|████▋     | 1200/2544 [06:48<07:29,  2.99it/s]Epoch [0/5] Batch 1200/2544                 loss D: -58.2140, loss G 272.2924
 51%|█████     | 1300/2544 [07:22<06:53,  3.01it/s]Epoch [0/5] Batch 1300/2544                 loss D: -57.0140, loss G 255.1894
 55%|█████▌    | 1400/2544 [07:56<06:22,  2.99it/s]Epoch [0/5] Batch 1400/2544                 loss D: -62.6614, loss G 253.4103
 59%|█████▉    | 1500/2544 [08:30<05:48,  3.00it/s]Epoch [0/5] Batch 1500/2544                 loss D: -46.2993, loss G 241.6155
 63%|██████▎   | 1600/2544 [09:03<05:10,  3.04it/s]Epoch [0/5] Batch 1600/2544                 loss D: -52.3221, loss G 226.0180
 67%|██████▋   | 1700/2544 [09:38<04:38,  3.03it/s]Epoch [0/5] Batch 1700/2544                 loss D: -46.5997, loss G 202.5125
 71%|███████   | 1800/2544 [10:11<04:05,  3.03it/s]Epoch [0/5] Batch 1800/2544                 loss D: -50.8334, loss G 239.6817
 75%|███████▍  | 1900/2544 [10:45<03:31,  3.04it/s]Epoch [0/5] Batch 1900/2544                 loss D: -36.9496, loss G 259.8300
 79%|███████▊  | 2000/2544 [11:19<03:00,  3.01it/s]Epoch [0/5] Batch 2000/2544                 loss D: -45.8228, loss G 214.4014
 83%|████████▎ | 2100/2544 [11:54<02:30,  2.95it/s]Epoch [0/5] Batch 2100/2544                 loss D: -43.0570, loss G 215.4970
 86%|████████▋ | 2200/2544 [12:27<01:53,  3.02it/s]Epoch [0/5] Batch 2200/2544                 loss D: -45.4389, loss G 257.6872
 90%|█████████ | 2300/2544 [13:01<01:20,  3.03it/s]Epoch [0/5] Batch 2300/2544                 loss D: -41.2562, loss G 220.0479
 94%|█████████▍| 2400/2544 [13:35<00:47,  3.04it/s]Epoch [0/5] Batch 2400/2544                 loss D: -36.3074, loss G 216.7901
 98%|█████████▊| 2500/2544 [14:09<00:14,  3.02it/s]Epoch [0/5] Batch 2500/2544                 loss D: -41.8835, loss G 219.8947
100%|██████████| 2544/2544 [14:25<00:00,  2.94it/s]
  4%|▍         | 100/2544 [00:33<13:23,  3.04it/s]Epoch [1/5] Batch 100/2544                 loss D: -41.6577, loss G 215.7390
  8%|▊         | 200/2544 [01:07<12:48,  3.05it/s]Epoch [1/5] Batch 200/2544                 loss D: -52.4268, loss G 212.4439
 12%|█▏        | 300/2544 [01:41<12:22,  3.02it/s]Epoch [1/5] Batch 300/2544                 loss D: -38.8915, loss G 205.8223
 16%|█▌        | 400/2544 [02:15<11:54,  3.00it/s]Epoch [1/5] Batch 400/2544                 loss D: -59.0275, loss G 180.6024
 20%|█▉        | 500/2544 [02:49<11:19,  3.01it/s]Epoch [1/5] Batch 500/2544                 loss D: -46.9554, loss G 212.3527
 24%|██▎       | 600/2544 [03:23<10:41,  3.03it/s]Epoch [1/5] Batch 600/2544                 loss D: -49.1497, loss G 234.1687
 28%|██▊       | 700/2544 [03:57<10:14,  3.00it/s]Epoch [1/5] Batch 700/2544                 loss D: -39.4024, loss G 256.0041
 31%|███▏      | 800/2544 [04:30<09:33,  3.04it/s]Epoch [1/5] Batch 800/2544                 loss D: -36.7320, loss G 252.0015
 35%|███▌      | 900/2544 [05:04<09:20,  2.93it/s]Epoch [1/5] Batch 900/2544                 loss D: -35.6667, loss G 218.6664
 39%|███▉      | 1000/2544 [05:38<08:31,  3.02it/s]Epoch [1/5] Batch 1000/2544                 loss D: -42.6797, loss G 224.2030
 43%|████▎     | 1100/2544 [06:12<07:59,  3.01it/s]Epoch [1/5] Batch 1100/2544                 loss D: -41.3592, loss G 237.8667
 47%|████▋     | 1200/2544 [06:46<07:34,  2.96it/s]Epoch [1/5] Batch 1200/2544                 loss D: -37.2452, loss G 195.2545
 51%|█████     | 1300/2544 [07:20<06:55,  3.00it/s]Epoch [1/5] Batch 1300/2544                 loss D: -39.9216, loss G 226.3224
 55%|█████▌    | 1400/2544 [07:54<06:15,  3.05it/s]Epoch [1/5] Batch 1400/2544                 loss D: -26.3072, loss G 240.6549
 59%|█████▉    | 1500/2544 [08:28<05:42,  3.05it/s]Epoch [1/5] Batch 1500/2544                 loss D: -28.4555, loss G 265.6730
 63%|██████▎   | 1600/2544 [09:02<05:12,  3.03it/s]Epoch [1/5] Batch 1600/2544                 loss D: -30.9308, loss G 240.0450
 67%|██████▋   | 1700/2544 [09:36<04:39,  3.02it/s]Epoch [1/5] Batch 1700/2544                 loss D: -33.0919, loss G 234.0612
 71%|███████   | 1800/2544 [10:10<04:06,  3.02it/s]Epoch [1/5] Batch 1800/2544                 loss D: -25.5644, loss G 257.9753
 75%|███████▍  | 1900/2544 [10:44<03:34,  3.00it/s]Epoch [1/5] Batch 1900/2544                 loss D: -32.3890, loss G 247.0092
 79%|███████▊  | 2000/2544 [11:18<02:59,  3.04it/s]Epoch [1/5] Batch 2000/2544                 loss D: -38.4218, loss G 220.3285
 83%|████████▎ | 2100/2544 [11:52<02:27,  3.02it/s]Epoch [1/5] Batch 2100/2544                 loss D: -43.6024, loss G 227.5622
 86%|████████▋ | 2200/2544 [12:25<01:52,  3.05it/s]Epoch [1/5] Batch 2200/2544                 loss D: -37.6499, loss G 244.9924
 90%|█████████ | 2300/2544 [12:59<01:20,  3.05it/s]Epoch [1/5] Batch 2300/2544                 loss D: -39.2080, loss G 243.6164
 94%|█████████▍| 2400/2544 [13:33<00:47,  3.03it/s]Epoch [1/5] Batch 2400/2544                 loss D: -32.6713, loss G 230.4651
 98%|█████████▊| 2500/2544 [14:07<00:14,  3.03it/s]Epoch [1/5] Batch 2500/2544                 loss D: -27.2687, loss G 256.7977
100%|██████████| 2544/2544 [14:23<00:00,  2.95it/s]
  4%|▍         | 100/2544 [00:33<13:22,  3.05it/s]Epoch [2/5] Batch 100/2544                 loss D: -40.4479, loss G 224.2083
  8%|▊         | 200/2544 [01:07<12:56,  3.02it/s]Epoch [2/5] Batch 200/2544                 loss D: -30.1567, loss G 266.3693
 12%|█▏        | 300/2544 [01:41<12:28,  3.00it/s]Epoch [2/5] Batch 300/2544                 loss D: -20.1982, loss G 253.9396
 16%|█▌        | 400/2544 [02:15<11:53,  3.00it/s]Epoch [2/5] Batch 400/2544                 loss D: -40.6860, loss G 273.0427
 20%|█▉        | 500/2544 [02:49<11:17,  3.02it/s]Epoch [2/5] Batch 500/2544                 loss D: -34.5164, loss G 266.3486
 24%|██▎       | 600/2544 [03:22<10:43,  3.02it/s]Epoch [2/5] Batch 600/2544                 loss D: -36.0207, loss G 257.4160
 28%|██▊       | 700/2544 [03:57<10:08,  3.03it/s]Epoch [2/5] Batch 700/2544                 loss D: -33.9337, loss G 265.9837
 31%|███▏      | 800/2544 [04:31<09:40,  3.01it/s]Epoch [2/5] Batch 800/2544                 loss D: -23.1663, loss G 277.1736
 35%|███▌      | 900/2544 [05:05<09:12,  2.98it/s]Epoch [2/5] Batch 900/2544                 loss D: -31.1251, loss G 281.4189
 39%|███▉      | 1000/2544 [05:39<08:35,  2.99it/s]Epoch [2/5] Batch 1000/2544                 loss D: -34.5070, loss G 265.6796
 43%|████▎     | 1100/2544 [06:13<08:13,  2.92it/s]Epoch [2/5] Batch 1100/2544                 loss D: -35.9378, loss G 246.8654
 47%|████▋     | 1200/2544 [06:48<07:36,  2.95it/s]Epoch [2/5] Batch 1200/2544                 loss D: -37.0740, loss G 299.2020
 51%|█████     | 1300/2544 [07:22<06:56,  2.99it/s]Epoch [2/5] Batch 1300/2544                 loss D: -44.6918, loss G 281.0155
 55%|█████▌    | 1400/2544 [07:56<06:21,  3.00it/s]Epoch [2/5] Batch 1400/2544                 loss D: -30.8230, loss G 276.7671
 59%|█████▉    | 1500/2544 [08:30<05:47,  3.01it/s]Epoch [2/5] Batch 1500/2544                 loss D: -28.3223, loss G 258.6471
 63%|██████▎   | 1600/2544 [09:05<05:13,  3.01it/s]Epoch [2/5] Batch 1600/2544                 loss D: -40.7852, loss G 272.3834
 67%|██████▋   | 1700/2544 [09:39<04:42,  2.99it/s]Epoch [2/5] Batch 1700/2544                 loss D: -25.9250, loss G 310.7675
 71%|███████   | 1800/2544 [10:13<04:06,  3.02it/s]Epoch [2/5] Batch 1800/2544                 loss D: -36.4320, loss G 337.2147
 75%|███████▍  | 1900/2544 [10:48<03:37,  2.96it/s]Epoch [2/5] Batch 1900/2544                 loss D: -33.5460, loss G 308.4041
 79%|███████▊  | 2000/2544 [11:22<03:03,  2.96it/s]Epoch [2/5] Batch 2000/2544                 loss D: -31.9844, loss G 308.6356
 83%|████████▎ | 2100/2544 [11:56<02:28,  3.00it/s]Epoch [2/5] Batch 2100/2544                 loss D: -35.2205, loss G 299.8477
 86%|████████▋ | 2200/2544 [12:30<01:55,  2.99it/s]Epoch [2/5] Batch 2200/2544                 loss D: -26.6987, loss G 314.4282
 90%|█████████ | 2300/2544 [13:05<01:20,  3.03it/s]Epoch [2/5] Batch 2300/2544                 loss D: -35.2502, loss G 234.9756
 94%|█████████▍| 2400/2544 [13:39<00:47,  3.01it/s]Epoch [2/5] Batch 2400/2544                 loss D: -38.0723, loss G 314.1130
 98%|█████████▊| 2500/2544 [14:13<00:14,  3.02it/s]Epoch [2/5] Batch 2500/2544                 loss D: -27.7045, loss G 276.8731
100%|██████████| 2544/2544 [14:29<00:00,  2.93it/s]
  4%|▍         | 100/2544 [00:33<13:35,  3.00it/s]Epoch [3/5] Batch 100/2544                 loss D: -41.2577, loss G 302.3690
  8%|▊         | 200/2544 [01:07<12:56,  3.02it/s]Epoch [3/5] Batch 200/2544                 loss D: -25.6431, loss G 286.0270
 12%|█▏        | 300/2544 [01:41<13:03,  2.86it/s]Epoch [3/5] Batch 300/2544                 loss D: -32.2403, loss G 283.3033
 16%|█▌        | 400/2544 [02:16<11:56,  2.99it/s]Epoch [3/5] Batch 400/2544                 loss D: -45.6157, loss G 305.5210
 20%|█▉        | 500/2544 [02:50<11:21,  3.00it/s]Epoch [3/5] Batch 500/2544                 loss D: -24.1838, loss G 287.0252
 24%|██▎       | 600/2544 [03:24<11:02,  2.93it/s]Epoch [3/5] Batch 600/2544                 loss D: -44.4474, loss G 337.2515
 28%|██▊       | 700/2544 [03:59<10:16,  2.99it/s]Epoch [3/5] Batch 700/2544                 loss D: -29.3686, loss G 290.4105
 31%|███▏      | 800/2544 [04:33<09:45,  2.98it/s]Epoch [3/5] Batch 800/2544                 loss D: -27.4056, loss G 325.7361
 35%|███▌      | 900/2544 [05:07<09:15,  2.96it/s]Epoch [3/5] Batch 900/2544                 loss D: -28.9386, loss G 301.9965
 39%|███▉      | 1000/2544 [05:41<08:39,  2.97it/s]Epoch [3/5] Batch 1000/2544                 loss D: -24.5247, loss G 296.9366
 43%|████▎     | 1100/2544 [06:15<08:00,  3.00it/s]Epoch [3/5] Batch 1100/2544                 loss D: -25.5075, loss G 291.7130
 47%|████▋     | 1200/2544 [06:50<07:34,  2.96it/s]Epoch [3/5] Batch 1200/2544                 loss D: -28.3246, loss G 301.0796
 51%|█████     | 1300/2544 [07:24<06:58,  2.97it/s]Epoch [3/5] Batch 1300/2544                 loss D: -29.8081, loss G 273.9962
 55%|█████▌    | 1400/2544 [07:58<06:23,  2.99it/s]Epoch [3/5] Batch 1400/2544                 loss D: -39.0963, loss G 339.2273
 59%|█████▉    | 1500/2544 [08:32<05:47,  3.01it/s]Epoch [3/5] Batch 1500/2544                 loss D: -25.3274, loss G 327.3229
 63%|██████▎   | 1600/2544 [09:06<05:15,  2.99it/s]Epoch [3/5] Batch 1600/2544                 loss D: -23.6694, loss G 329.1693
 67%|██████▋   | 1700/2544 [09:41<04:40,  3.01it/s]Epoch [3/5] Batch 1700/2544                 loss D: -33.7408, loss G 292.1924
 71%|███████   | 1800/2544 [10:15<04:08,  3.00it/s]Epoch [3/5] Batch 1800/2544                 loss D: -26.8545, loss G 335.4372
 75%|███████▍  | 1900/2544 [10:49<03:33,  3.02it/s]Epoch [3/5] Batch 1900/2544                 loss D: -25.5063, loss G 293.8122
 79%|███████▊  | 2000/2544 [11:23<03:03,  2.97it/s]Epoch [3/5] Batch 2000/2544                 loss D: -30.4844, loss G 329.3345
 83%|████████▎ | 2100/2544 [11:58<02:30,  2.94it/s]Epoch [3/5] Batch 2100/2544                 loss D: -26.3003, loss G 346.6030
 86%|████████▋ | 2200/2544 [12:32<01:57,  2.93it/s]Epoch [3/5] Batch 2200/2544                 loss D: -30.3067, loss G 292.0861
 90%|█████████ | 2300/2544 [13:06<01:21,  3.01it/s]Epoch [3/5] Batch 2300/2544                 loss D: -22.1223, loss G 304.5031
 94%|█████████▍| 2400/2544 [13:40<00:47,  3.02it/s]Epoch [3/5] Batch 2400/2544                 loss D: -35.0515, loss G 289.3695
 98%|█████████▊| 2500/2544 [14:15<00:14,  2.98it/s]Epoch [3/5] Batch 2500/2544                 loss D: -23.3481, loss G 320.9230
100%|██████████| 2544/2544 [14:30<00:00,  2.92it/s]
  4%|▍         | 100/2544 [00:33<13:27,  3.03it/s]Epoch [4/5] Batch 100/2544                 loss D: -33.6555, loss G 249.0131
  8%|▊         | 200/2544 [01:07<12:55,  3.02it/s]Epoch [4/5] Batch 200/2544                 loss D: -36.1953, loss G 253.6497
 12%|█▏        | 300/2544 [01:41<12:22,  3.02it/s]Epoch [4/5] Batch 300/2544                 loss D: -31.1506, loss G 300.0957
 16%|█▌        | 400/2544 [02:15<11:57,  2.99it/s]Epoch [4/5] Batch 400/2544                 loss D: -24.4163, loss G 294.1598
 20%|█▉        | 500/2544 [02:50<11:21,  3.00it/s]Epoch [4/5] Batch 500/2544                 loss D: -29.4825, loss G 286.2874
 24%|██▎       | 600/2544 [03:24<10:55,  2.97it/s]Epoch [4/5] Batch 600/2544                 loss D: -25.9677, loss G 273.3749
 28%|██▊       | 700/2544 [03:58<10:23,  2.96it/s]Epoch [4/5] Batch 700/2544                 loss D: -22.5826, loss G 340.2480
 31%|███▏      | 800/2544 [04:32<09:35,  3.03it/s]Epoch [4/5] Batch 800/2544                 loss D: -27.8095, loss G 305.0647
 35%|███▌      | 900/2544 [05:06<09:07,  3.00it/s]Epoch [4/5] Batch 900/2544                 loss D: -26.0085, loss G 316.5270
 39%|███▉      | 1000/2544 [05:40<08:34,  3.00it/s]Epoch [4/5] Batch 1000/2544                 loss D: -26.2793, loss G 325.3823
 43%|████▎     | 1100/2544 [06:14<08:02,  3.00it/s]Epoch [4/5] Batch 1100/2544                 loss D: -25.1843, loss G 311.3757
 47%|████▋     | 1200/2544 [06:49<07:27,  3.00it/s]Epoch [4/5] Batch 1200/2544                 loss D: -28.2656, loss G 284.7750
 51%|█████     | 1300/2544 [07:23<06:52,  3.01it/s]Epoch [4/5] Batch 1300/2544                 loss D: -25.2730, loss G 281.6030
 55%|█████▌    | 1400/2544 [07:57<06:26,  2.96it/s]Epoch [4/5] Batch 1400/2544                 loss D: -33.9147, loss G 318.7432
 59%|█████▉    | 1500/2544 [08:31<05:48,  3.00it/s]Epoch [4/5] Batch 1500/2544                 loss D: -33.0293, loss G 278.9810
 63%|██████▎   | 1600/2544 [09:06<05:13,  3.01it/s]Epoch [4/5] Batch 1600/2544                 loss D: -26.3261, loss G 284.2968
 67%|██████▋   | 1700/2544 [09:40<04:40,  3.01it/s]Epoch [4/5] Batch 1700/2544                 loss D: -19.3688, loss G 296.4881
 71%|███████   | 1800/2544 [10:14<04:07,  3.00it/s]Epoch [4/5] Batch 1800/2544                 loss D: -23.5028, loss G 286.4407
 75%|███████▍  | 1900/2544 [10:48<03:35,  2.98it/s]Epoch [4/5] Batch 1900/2544                 loss D: -17.7591, loss G 273.0345
 79%|███████▊  | 2000/2544 [11:23<03:02,  2.98it/s]Epoch [4/5] Batch 2000/2544                 loss D: -38.8020, loss G 269.7662
 83%|████████▎ | 2100/2544 [11:57<02:27,  3.01it/s]Epoch [4/5] Batch 2100/2544                 loss D: -21.0912, loss G 299.3576
 86%|████████▋ | 2200/2544 [12:31<01:54,  3.01it/s]Epoch [4/5] Batch 2200/2544                 loss D: -25.4820, loss G 307.8739
 90%|█████████ | 2300/2544 [13:05<01:22,  2.97it/s]Epoch [4/5] Batch 2300/2544                 loss D: -16.1946, loss G 300.9348
 94%|█████████▍| 2400/2544 [13:39<00:48,  2.96it/s]Epoch [4/5] Batch 2400/2544                 loss D: -26.1881, loss G 283.2641
 98%|█████████▊| 2500/2544 [14:14<00:14,  3.00it/s]Epoch [4/5] Batch 2500/2544                 loss D: -18.2454, loss G 323.2116
100%|██████████| 2544/2544 [14:29<00:00,  2.93it/s]