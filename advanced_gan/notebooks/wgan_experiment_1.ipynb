{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-24T16:12:52.077598Z",
     "start_time": "2024-10-24T16:12:46.162096Z"
    }
   },
   "source": [
    "import torch.nn as nn\n",
    "import torch "
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T16:12:52.092338Z",
     "start_time": "2024-10-24T16:12:52.087660Z"
    }
   },
   "cell_type": "code",
   "source": "print(torch.__version__)",
   "id": "584443534a34f8f0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1+cu124\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T16:12:53.053678Z",
     "start_time": "2024-10-24T16:12:52.122318Z"
    }
   },
   "cell_type": "code",
   "source": "print(torch.cuda.is_available())",
   "id": "e47e5c10775027d5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T16:13:02.838327Z",
     "start_time": "2024-10-24T16:12:53.060714Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torchvision\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as dataloader\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ],
   "id": "7cf8c9f132fd20bd",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T16:21:54.839334Z",
     "start_time": "2024-10-24T16:21:54.834126Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, channels_img, features_d):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                channels_img, features_d, kernel_size=4, stride=2, padding=1\n",
    "            ),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            self._block(features_d, features_d * 2, 4, 2, 1),\n",
    "            self._block(features_d * 2, features_d * 4, 4, 2, 1),\n",
    "            self._block(features_d * 4, features_d * 8, 4, 2, 1),\n",
    "            self._block(features_d * 8, features_d * 16, 4, 2, 1),\n",
    "            \n",
    "            nn.Conv2d(features_d * 16, 1, kernel_size=4, stride=2, padding=0),\n",
    "        )\n",
    "    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels,\n",
    "                out_channels,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=stride,\n",
    "                padding=padding,\n",
    "                bias=False,\n",
    "            ),\n",
    "            nn.InstanceNorm2d(out_channels),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.disc(x)\n",
    "    \n"
   ],
   "id": "18438692178bcca6",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T16:13:02.851987Z",
     "start_time": "2024-10-24T16:13:02.844380Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, channels_noise, channels_img, features_g):\n",
    "        super(Generator, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            self._block(channels_noise, features_g * 16, 4, 1, 0), # 4x4\n",
    "            self._block(features_g * 16, features_g * 8, 4, 2, 1), # 8x8 \n",
    "            self._block(features_g * 8, features_g * 4, 4, 2, 1), # 16 x 16\n",
    "            self._block(features_g * 4, features_g * 2, 4, 2, 1), # 32 x 32\n",
    "            self._block(features_g * 2, features_g, 4, 2, 1), # 64 x 64\n",
    "            nn.ConvTranspose2d(\n",
    "                features_g * 1, channels_img, kernel_size=4, stride=2, padding=1\n",
    "            ),\n",
    "            # 128 x 128\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "        \n",
    "    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels,\n",
    "                out_channels,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=stride,\n",
    "                padding=padding,\n",
    "                bias=False,\n",
    "            ),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ],
   "id": "e32b8da0955f22c3",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T20:04:43.349289Z",
     "start_time": "2024-10-23T20:04:43.345500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def initialize_weights(model):\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)):\n",
    "            nn.init.normal(m.weight.data, 0.0, 0.02)"
   ],
   "id": "46c2bbb5c730d965",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T16:13:39.797010Z",
     "start_time": "2024-10-24T16:13:39.790979Z"
    }
   },
   "cell_type": "code",
   "source": "from torchsummary import summary",
   "id": "974603d4897e0200",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T16:13:26.637650Z",
     "start_time": "2024-10-24T16:13:26.631978Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "LEARNING_RATE = 1e-4\n",
    "BATCH_SIZE = 64\n",
    "IMG_SIZE = 64\n",
    "CHANNELS_IMG = 3\n",
    "Z_DIM = 100\n",
    "NUM_CLASSES = 5\n",
    "FEATURES_CRITIC = 64\n",
    "FEATURES_GEN = 64\n",
    "CRITIC_ITERATIONS = 5\n",
    "NUM_EPOCHS = 5\n",
    "LAMBDA_GP = 10"
   ],
   "id": "cb3e40bfaf20eece",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T16:21:58.616705Z",
     "start_time": "2024-10-24T16:21:58.584753Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def test_classes():\n",
    "    N, in_channels, H, W = 8, 3, 128, 128\n",
    "    noise_dim = 100\n",
    "    x = torch.randn((N, in_channels, H, W)).to(device)\n",
    "    disc = Discriminator(in_channels, 8).to(device)\n",
    "    # assert disc(x).shape == (N, 1, 1, 1), \"Discriminator test failed\"\n",
    "    print(summary(disc, input_size=(in_channels, H, H)))\n",
    "    gen = Generator(channels_noise=noise_dim, channels_img=in_channels, features_g=8).to(device)\n",
    "    z = torch.randn((N, noise_dim, 1, 1)).to(device)\n",
    "    # assert gen(z).shape == (N, in_channels, H, W), \" Generator test failed\"\n",
    "    print(summary(gen, input_size=(noise_dim, 1, 1)))\n",
    "    \n",
    "test_classes()"
   ],
   "id": "89f6acd740895473",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 8, 64, 64]             392\n",
      "         LeakyReLU-2            [-1, 8, 64, 64]               0\n",
      "            Conv2d-3           [-1, 16, 32, 32]           2,048\n",
      "    InstanceNorm2d-4           [-1, 16, 32, 32]               0\n",
      "         LeakyReLU-5           [-1, 16, 32, 32]               0\n",
      "            Conv2d-6           [-1, 32, 16, 16]           8,192\n",
      "    InstanceNorm2d-7           [-1, 32, 16, 16]               0\n",
      "         LeakyReLU-8           [-1, 32, 16, 16]               0\n",
      "            Conv2d-9             [-1, 64, 8, 8]          32,768\n",
      "   InstanceNorm2d-10             [-1, 64, 8, 8]               0\n",
      "        LeakyReLU-11             [-1, 64, 8, 8]               0\n",
      "           Conv2d-12            [-1, 128, 4, 4]         131,072\n",
      "   InstanceNorm2d-13            [-1, 128, 4, 4]               0\n",
      "        LeakyReLU-14            [-1, 128, 4, 4]               0\n",
      "           Conv2d-15              [-1, 1, 1, 1]           2,049\n",
      "================================================================\n",
      "Total params: 176,521\n",
      "Trainable params: 176,521\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.19\n",
      "Forward/backward pass size (MB): 1.20\n",
      "Params size (MB): 0.67\n",
      "Estimated Total Size (MB): 2.06\n",
      "----------------------------------------------------------------\n",
      "None\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "   ConvTranspose2d-1            [-1, 128, 4, 4]         204,800\n",
      "       BatchNorm2d-2            [-1, 128, 4, 4]             256\n",
      "              ReLU-3            [-1, 128, 4, 4]               0\n",
      "   ConvTranspose2d-4             [-1, 64, 8, 8]         131,072\n",
      "       BatchNorm2d-5             [-1, 64, 8, 8]             128\n",
      "              ReLU-6             [-1, 64, 8, 8]               0\n",
      "   ConvTranspose2d-7           [-1, 32, 16, 16]          32,768\n",
      "       BatchNorm2d-8           [-1, 32, 16, 16]              64\n",
      "              ReLU-9           [-1, 32, 16, 16]               0\n",
      "  ConvTranspose2d-10           [-1, 16, 32, 32]           8,192\n",
      "      BatchNorm2d-11           [-1, 16, 32, 32]              32\n",
      "             ReLU-12           [-1, 16, 32, 32]               0\n",
      "  ConvTranspose2d-13            [-1, 8, 64, 64]           2,048\n",
      "      BatchNorm2d-14            [-1, 8, 64, 64]              16\n",
      "             ReLU-15            [-1, 8, 64, 64]               0\n",
      "  ConvTranspose2d-16          [-1, 3, 128, 128]             387\n",
      "             Tanh-17          [-1, 3, 128, 128]               0\n",
      "================================================================\n",
      "Total params: 379,763\n",
      "Trainable params: 379,763\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 2.20\n",
      "Params size (MB): 1.45\n",
      "Estimated Total Size (MB): 3.65\n",
      "----------------------------------------------------------------\n",
      "None\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T20:35:14.591929Z",
     "start_time": "2024-10-23T20:35:14.586498Z"
    }
   },
   "cell_type": "code",
   "source": [
    "transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            [0.5 for _ in range(CHANNELS_IMG)], [0.5 for _ in range(CHANNELS_IMG)]\n",
    "        ),\n",
    "    ]\n",
    ")"
   ],
   "id": "99e65eac7e37bbf5",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T20:38:27.361988Z",
     "start_time": "2024-10-23T20:38:27.357819Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def gradient_penalty(critic, real, fake, device):\n",
    "    BATCH_SIZE, C, H, W = real.shape\n",
    "    epsilon = torch.rand((BATCH_SIZE, 1, 1, 1)).repeat(1, C, H, W).to(device)\n",
    "    interpolated_images = real * epsilon + fake * (1 - epsilon)\n",
    "    \n",
    "    \n",
    "    # calcuated mixed scores\n",
    "    mixed_scores = critic(interpolated_images)\n",
    "    \n",
    "    gradient = torch.autograd.grad(\n",
    "        inputs=interpolated_images,\n",
    "        outputs=mixed_scores,\n",
    "        grad_outputs=torch.ones_like(mixed_scores),\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "    )[0]\n",
    "    \n",
    "    gradient = gradient.view(gradient.shape[0], -1) # flattening\n",
    "    gradient_norm = gradient.norm(2, dim=1) # taking norm of flattened dim\n",
    "    gradient_penalty = torch.mean((gradient_norm - 1) ** 2)\n",
    "    return gradient_penalty"
   ],
   "id": "168a5821a1906502",
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T19:46:57.740571Z",
     "start_time": "2024-10-23T19:46:57.736795Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def save_checkpoint(state, filename='celeba_wgan_gp'):\n",
    "    print(\"-> saving checkpoint\")\n",
    "    torch.save(state, filename)\n",
    "    \n",
    "def load_checkpoint(filename, gen, disc):\n",
    "    print(\"-> loading checkpoint\")\n",
    "    gen.load_state_dict(torch.load(filename))\n",
    "    disc.load_state_dict(torch.load(filename))"
   ],
   "id": "bbdf93ed04597b72",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T19:51:16.273191Z",
     "start_time": "2024-10-23T19:51:16.269460Z"
    }
   },
   "cell_type": "code",
   "source": "from torch.utils.data import DataLoader",
   "id": "b3982d44fe0e5aec",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T20:35:36.496856Z",
     "start_time": "2024-10-23T20:35:20.305725Z"
    }
   },
   "cell_type": "code",
   "source": [
    "celeba_dataset = datasets.CelebA(root='data',\n",
    "                                 split='train',\n",
    "                                 transform=transforms,\n",
    "                                 download=True)\n",
    "celeba_loader = DataLoader(dataset=celeba_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ],
   "id": "bf1ed0b3b24eb123",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T20:04:49.852469Z",
     "start_time": "2024-10-23T20:04:49.680400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "gen = Generator(Z_DIM, CHANNELS_IMG, FEATURES_GEN).to(device)   \n",
    "disc = Discriminator(CHANNELS_IMG, FEATURES_CRITIC).to(device)\n",
    "\n",
    "initialize_weights(gen)\n",
    "initialize_weights(disc)"
   ],
   "id": "ab3ab3439ded189",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\meddi\\AppData\\Local\\Temp\\ipykernel_14576\\3099560224.py:4: FutureWarning: `nn.init.normal` is now deprecated in favor of `nn.init.normal_`.\n",
      "  nn.init.normal(m.weight.data, 0.0, 0.02)\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "b87c9c396111ba3e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T20:05:06.008133Z",
     "start_time": "2024-10-23T20:05:06.004802Z"
    }
   },
   "cell_type": "code",
   "source": [
    "opt_gen = optim.Adam(gen.parameters(), lr=LEARNING_RATE)\n",
    "opt_disc = optim.Adam(disc.parameters(), lr=LEARNING_RATE, betas=(0.0, 0.9))"
   ],
   "id": "d92a0be710eb6c6",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T20:18:30.079095Z",
     "start_time": "2024-10-23T20:18:30.008348Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fixed_noise = torch.randn(32, Z_DIM, 1, 1).to(device)\n",
    "writer_real = SummaryWriter(f\"logs/WPGAN_CELEBA/base/real\")\n",
    "writer_fake = SummaryWriter(f\"logs/WPGAN_CELEBA/base/fake\")\n",
    "\n",
    "step = 0\n",
    "img_idx = 0\n",
    "gen.train()\n",
    "disc.train()"
   ],
   "id": "617cc216bb777d80",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (disc): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.2)\n",
       "    (2): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (2): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (2): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (2): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "    (5): Conv2d(512, 1, kernel_size=(4, 4), stride=(2, 2))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T20:08:30.227049Z",
     "start_time": "2024-10-23T20:08:30.224179Z"
    }
   },
   "cell_type": "code",
   "source": "from tqdm import tqdm",
   "id": "bf4e75584f11bb3f",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T20:16:59.053652Z",
     "start_time": "2024-10-23T20:16:59.042969Z"
    }
   },
   "cell_type": "code",
   "source": "from torchvision.transforms import ToPILImage",
   "id": "3b05e613d845d808",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T20:39:45.916366Z",
     "start_time": "2024-10-23T20:39:06.257016Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# main training loop\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    for batch_idx, (real, _) in enumerate(tqdm(celeba_loader)):\n",
    "        # print(real.shape)\n",
    "        real = real.to(device)\n",
    "        cur_batch_size = real.shape[0]\n",
    "        \n",
    "        # Train Discriminator\n",
    "        for _ in range(CRITIC_ITERATIONS):\n",
    "            noise = torch.randn(cur_batch_size, Z_DIM, 1, 1).to(device)\n",
    "            fake = gen(noise)\n",
    "            # print(\"fake shape\", fake.shape)\n",
    "            # print(\"real shape\", real.shape)\n",
    "            critical_real = disc(real).reshape(-1)\n",
    "            critical_fake = disc(fake).reshape(-1)\n",
    "            gp = gradient_penalty(disc, real, fake, device)\n",
    "            loss_disc = (\n",
    "                -(torch.mean(critical_real) - torch.mean(critical_fake)) + LAMBDA_GP * gp\n",
    "            )\n",
    "            disc.zero_grad()\n",
    "            loss_disc.backward(retain_graph=True)\n",
    "            opt_disc.step()\n",
    "            \n",
    "        # Train Generator\n",
    "        gen_fake = disc(fake).reshape(-1)\n",
    "        loss_gen = -torch.mean(gen_fake)\n",
    "        gen.zero_grad()\n",
    "        loss_gen.backward()\n",
    "        opt_gen.step()\n",
    "        \n",
    "        if batch_idx % 100 == 0 and batch_idx != 0:\n",
    "            print(\n",
    "                f\"Epoch [{epoch}/{NUM_EPOCHS}] Batch {batch_idx}/{len(celeba_loader)} \\\n",
    "                loss D: {loss_disc:.4f}, loss G {loss_gen:.4f}\"\n",
    "            )\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                fake = gen(fixed_noise)\n",
    "                \n",
    "                img_grid_real = torchvision.utils.make_grid(real[:32], normalize=True)\n",
    "                img_grid_fake = torchvision.utils.make_grid(fake[:32], normalize=True)\n",
    "                \n",
    "                writer_real.add_image(\"Real\", img_grid_real, global_step=step)\n",
    "                writer_fake.add_image(\"Fake\", img_grid_fake, global_step=step)\n",
    "                \n",
    "                to_pil = ToPILImage()\n",
    "                \n",
    "                img_fake = to_pil(img_grid_fake)\n",
    "                img_fake.save(f\" ../images/base/fake/fake_images_grid_{img_idx}.png\"\n",
    "                             )\n",
    "            step += 1"
   ],
   "id": "22d0657515a82124",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/2544 [00:39<3:59:12,  5.66s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[51], line 16\u001B[0m\n\u001B[0;32m     14\u001B[0m critical_real \u001B[38;5;241m=\u001B[39m disc(real)\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     15\u001B[0m critical_fake \u001B[38;5;241m=\u001B[39m disc(fake)\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m---> 16\u001B[0m gp \u001B[38;5;241m=\u001B[39m \u001B[43mgradient_penalty\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdisc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreal\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfake\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     17\u001B[0m loss_disc \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m     18\u001B[0m     \u001B[38;5;241m-\u001B[39m(torch\u001B[38;5;241m.\u001B[39mmean(critical_real) \u001B[38;5;241m-\u001B[39m torch\u001B[38;5;241m.\u001B[39mmean(critical_fake)) \u001B[38;5;241m+\u001B[39m LAMBDA_GP \u001B[38;5;241m*\u001B[39m gp\n\u001B[0;32m     19\u001B[0m )\n\u001B[0;32m     20\u001B[0m disc\u001B[38;5;241m.\u001B[39mzero_grad()\n",
      "Cell \u001B[1;32mIn[49], line 3\u001B[0m, in \u001B[0;36mgradient_penalty\u001B[1;34m(critic, real, fake, device)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mgradient_penalty\u001B[39m(critic, real, fake, device):\n\u001B[0;32m      2\u001B[0m     BATCH_SIZE, C, H, W \u001B[38;5;241m=\u001B[39m real\u001B[38;5;241m.\u001B[39mshape\n\u001B[1;32m----> 3\u001B[0m     epsilon \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrand\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[43mBATCH_SIZE\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrepeat\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mC\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mH\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mW\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      4\u001B[0m     interpolated_images \u001B[38;5;241m=\u001B[39m real \u001B[38;5;241m*\u001B[39m epsilon \u001B[38;5;241m+\u001B[39m fake \u001B[38;5;241m*\u001B[39m (\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m-\u001B[39m epsilon)\n\u001B[0;32m      7\u001B[0m     \u001B[38;5;66;03m# calcuated mixed scores\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "45b52051711a452"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
