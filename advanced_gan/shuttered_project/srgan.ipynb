{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-22T20:11:30.357968Z",
     "start_time": "2024-10-22T20:11:30.354451Z"
    }
   },
   "source": [
    "import torch\n",
    "from torch import nn"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T20:11:30.400160Z",
     "start_time": "2024-10-22T20:11:30.391331Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "LOAD_MODEL = True\n",
    "SAVE_MODEL = True\n",
    "CHECKPOINT_GEN = \"gen\"\n",
    "CHECKPOINT_DISC = \"disc\"\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "LEARNING_RATE = 1e-4\n",
    "NUM_EPOCHS = 100\n",
    "BATCH_SIZE = 16\n",
    "NUM_WORKERS = 4\n",
    "HIGH_RES = 96\n",
    "LOW_RES = HIGH_RES // 4\n",
    "IMG_CHANNELS = 3\n",
    "\n",
    "highres_transform = A.Compose(\n",
    "    [\n",
    "        A.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "lowres_transform = A.Compose(\n",
    "    [\n",
    "        A.Resize(width=LOW_RES, height=LOW_RES, interpolation=Image.BICUBIC),\n",
    "        A.Normalize(mean=[0, 0, 0], std=[1, 1, 1]),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "both_transforms = A.Compose(\n",
    "    [\n",
    "        A.RandomCrop(width=HIGH_RES, height=HIGH_RES),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.RandomRotate90(p=0.5),\n",
    "    ]\n",
    ")\n",
    "\n",
    "test_transform = A.Compose(\n",
    "    [\n",
    "        A.Normalize(mean=[0, 0, 0], std=[1, 1, 1]),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")"
   ],
   "id": "2e1dd0a99f363907",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T20:11:30.423900Z",
     "start_time": "2024-10-22T20:11:30.417307Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    # conv -> BN -> Leaky/PRelu\n",
    "    def __init__(self, \n",
    "                 in_channels, \n",
    "                 out_channels, \n",
    "                 discriminator=False,\n",
    "                 use_act=True,\n",
    "                 use_bn=True, \n",
    "                 **kwargs\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.use_act = use_act\n",
    "        self.cnn = nn.Conv2d(in_channels, out_channels, **kwargs, bias=not use_bn)\n",
    "        self.bn = nn.BatchNorm2d(out_channels) if use_bn else nn.Identity()\n",
    "        self.act = (\n",
    "            nn.LeakyReLU(negative_slope=0.2, inplace=True)\n",
    "            if discriminator \n",
    "            else nn.PReLU(num_parameters=out_channels)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.act(self.bn(self.cnn(x))) if self.use_act else self.bn(self.cnn(x))\n",
    "        \n"
   ],
   "id": "d0a75a20b9140840",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T20:11:30.437443Z",
     "start_time": "2024-10-22T20:11:30.432790Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class UpsampleBlock(nn.Module):\n",
    "    def __init__(self, in_c, scale_factor):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_c, in_c * scale_factor ** 2, 3, 1, 1)\n",
    "        self.ps = nn.PixelShuffle(scale_factor) # in_c * 4, H, W --> in_c, H*2, W*2\n",
    "        self.act = nn.PReLU(num_parameters=in_c)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.act(self.ps(self.conv(x)))\n",
    "        "
   ],
   "id": "c466dcd0303a6f92",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T20:11:30.454135Z",
     "start_time": "2024-10-22T20:11:30.449490Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "        self.block1 = ConvBlock(\n",
    "            in_channels,\n",
    "            in_channels,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1\n",
    "        )\n",
    "        self.block2 = ConvBlock(\n",
    "            in_channels,\n",
    "            in_channels,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1,\n",
    "            use_act=False\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        out = self.block1(x)\n",
    "        out = self.block2(out)\n",
    "        return out + x"
   ],
   "id": "2835ee7e13b168ce",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T20:11:30.469445Z",
     "start_time": "2024-10-22T20:11:30.462859Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, in_channels=3, num_channels=64, num_blocks=16):\n",
    "        super().__init__()\n",
    "        self.initial = ConvBlock(\n",
    "            in_channels,\n",
    "            num_channels,\n",
    "            kernel_size=9,\n",
    "            stride=1,\n",
    "            padding=4,\n",
    "            use_bn=False)\n",
    "        self.residuals = nn.Sequential(*[ResidualBlock(num_channels) for _ in range(num_blocks)])\n",
    "        self.convblock = ConvBlock(num_channels, num_channels, kernel_size=3, stride=1, padding=1, use_act=False)\n",
    "        self.upsamples = nn.Sequential(UpsampleBlock(num_channels, scale_factor=2), UpsampleBlock(num_channels, scale_factor=2)) \n",
    "        self.final = nn.Conv2d(num_channels, in_channels, kernel_size=9, stride=1, padding=4)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        initial = self.initial(x)\n",
    "        x = self.residuals(initial)\n",
    "        x = self.convblock(x) + initial\n",
    "        x = self.upsamples(x)\n",
    "        return torch.tanh(self.final(x))"
   ],
   "id": "11b30a2e974f109e",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T20:11:30.489702Z",
     "start_time": "2024-10-22T20:11:30.483605Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_channels=3, features=[64, 64, 128, 128, 256, 256, 512, 512]):\n",
    "        super().__init__()\n",
    "        blocks = []\n",
    "        for idx, feature in enumerate(features):\n",
    "            blocks.append(\n",
    "                ConvBlock(\n",
    "                    in_channels,\n",
    "                    feature,\n",
    "                    kernel_size=3,\n",
    "                    stride=1 + (idx % 2), # adds +1 to stride for each 2nd idx (since idx starts at 0)\n",
    "                    padding=1,\n",
    "                    discriminator=True,\n",
    "                    use_act=True,\n",
    "                    use_bn=False if idx==0 else True,\n",
    "                )\n",
    "            )\n",
    "            in_channels = feature\n",
    "            \n",
    "        self.blocks = nn.Sequential(*blocks)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((6, 6)), \n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512*6*6, 1024),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(1024, 1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.blocks(x)\n",
    "        return self.classifier(x)"
   ],
   "id": "e78d7a33d37b1950",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T20:11:31.776107Z",
     "start_time": "2024-10-22T20:11:30.511748Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def test():\n",
    "    low_resolution = 24\n",
    "    with torch.amp.autocast(device_type='cuda'):\n",
    "        x = torch.randn(5, 3, low_resolution, low_resolution)\n",
    "        gen = Generator()\n",
    "        gen_out = gen(x)\n",
    "        disc = Discriminator()\n",
    "        disc_out = disc(x)\n",
    "        \n",
    "        print(gen_out.shape, disc_out.shape)\n",
    "        \n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    test()"
   ],
   "id": "dd8b0c46f9ffbc21",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 96, 96]) torch.Size([5, 1])\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "writing loss function",
   "id": "cb7070875a552f0a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T20:11:33.496464Z",
     "start_time": "2024-10-22T20:11:31.788493Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from torchvision.models import vgg19"
   ],
   "id": "6a40ebcbd9f1fbe9",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T20:11:33.513016Z",
     "start_time": "2024-10-22T20:11:33.504937Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# phi_5, 5th conv layer before maxpooling but after activation\n",
    "\n",
    "class VGGLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.vgg = vgg19(pretrained=True).features[:36].eval().to(DEVICE)\n",
    "        self.loss = nn.MSELoss()\n",
    "        \n",
    "        for param in self.vgg.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "    def forward(self, input, target):\n",
    "        vgg_input_features = self.vgg(input)\n",
    "        vgg_target_features = self.vgg(target)\n",
    "        return self.loss(vgg_input_features, vgg_target_features)\n",
    "            \n",
    "        "
   ],
   "id": "e5347ce25cca8b45",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T20:15:17.518792Z",
     "start_time": "2024-10-22T20:15:17.511064Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import os\n",
    "import config\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "\n",
    "def gradient_penalty(critic, real, fake, device):\n",
    "    BATCH_SIZE, C, H, W = real.shape\n",
    "    alpha = torch.rand((BATCH_SIZE, 1, 1, 1)).repeat(1, C, H, W).to(device)\n",
    "    interpolated_images = real * alpha + fake.detach() * (1 - alpha)\n",
    "    interpolated_images.requires_grad_(True)\n",
    "\n",
    "    # Calculate critic scores\n",
    "    mixed_scores = critic(interpolated_images)\n",
    "\n",
    "    # Take the gradient of the scores with respect to the images\n",
    "    gradient = torch.autograd.grad(\n",
    "        inputs=interpolated_images,\n",
    "        outputs=mixed_scores,\n",
    "        grad_outputs=torch.ones_like(mixed_scores),\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "    )[0]\n",
    "    gradient = gradient.view(gradient.shape[0], -1)\n",
    "    gradient_norm = gradient.norm(2, dim=1)\n",
    "    gradient_penalty = torch.mean((gradient_norm - 1) ** 2)\n",
    "    return gradient_penalty\n",
    "\n",
    "\n",
    "def save_checkpoint(model, optimizer, filename=\"my_checkpoint\"):\n",
    "    print(\"=> Saving checkpoint\")\n",
    "    checkpoint = {\n",
    "        \"state_dict\": model.state_dict(),\n",
    "        \"optimizer\": optimizer.state_dict(),\n",
    "    }\n",
    "    torch.save(checkpoint, filename)\n",
    "\n",
    "\n",
    "def load_checkpoint(checkpoint_file, model, optimizer, lr):\n",
    "    print(\"=> Loading checkpoint\")\n",
    "    checkpoint = torch.load(checkpoint_file, map_location=DEVICE)\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
    "\n",
    "    # If we don't do this then it will just have learning rate of old checkpoint\n",
    "    # and it will lead to many hours of debugging \\:\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group[\"lr\"] = lr\n",
    "\n",
    "\n",
    "def plot_examples(low_res_folder, gen):\n",
    "    files = os.listdir(low_res_folder)\n",
    "\n",
    "    gen.eval()\n",
    "    for file in files:\n",
    "        image = Image.open(\"test_images/\" + file)\n",
    "        with torch.no_grad():\n",
    "            upscaled_img = gen(\n",
    "                test_transform(image=np.asarray(image))[\"image\"]\n",
    "                .unsqueeze(0)\n",
    "                .to(DEVICE)\n",
    "            )\n",
    "        save_image(upscaled_img * 0.5 + 0.5, f\"saved/{file}\")\n",
    "    gen.train()"
   ],
   "id": "5096fc090b026ddb",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T20:11:33.559125Z",
     "start_time": "2024-10-22T20:11:33.552654Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import config\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "class MyImageFolder(Dataset):\n",
    "    def __init__(self, root_dir):\n",
    "        super(MyImageFolder, self).__init__()\n",
    "        self.data = []\n",
    "        self.root_dir = root_dir\n",
    "        self.class_names = os.listdir(root_dir)\n",
    "\n",
    "        for index, name in enumerate(self.class_names):\n",
    "            files = os.listdir(os.path.join(root_dir, name))\n",
    "            self.data += list(zip(files, [index] * len(files)))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_file, label = self.data[index]\n",
    "        root_and_dir = os.path.join(self.root_dir, self.class_names[label])\n",
    "\n",
    "        image = np.array(Image.open(os.path.join(root_and_dir, img_file)))\n",
    "        image = both_transforms(image=image)[\"image\"]\n",
    "        high_res = highres_transform(image=image)[\"image\"]\n",
    "        low_res = lowres_transform(image=image)[\"image\"]\n",
    "        return low_res, high_res\n",
    "\n",
    "\n",
    "def test():\n",
    "    dataset = MyImageFolder(root_dir=\"new_data/\")\n",
    "    loader = DataLoader(dataset, batch_size=1, num_workers=8)\n",
    "\n",
    "    for low_res, high_res in loader:\n",
    "        print(low_res.shape)\n",
    "        print(high_res.shape)"
   ],
   "id": "66508b866f446313",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T20:18:41.882430Z",
     "start_time": "2024-10-22T20:18:40.229253Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import config\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "\n",
    "def train_fn(loader, disc, gen, opt_gen, opt_disc, mse, bce, vgg_loss):\n",
    "    loop = tqdm(loader, leave=True)\n",
    "\n",
    "    for idx, (low_res, high_res) in enumerate(loop):\n",
    "        high_res = high_res.to(DEVICE)\n",
    "        low_res = low_res.to(DEVICE)\n",
    "        \n",
    "        ### Train Discriminator: max log(D(x)) + log(1 - D(G(z)))\n",
    "        fake = gen(low_res)\n",
    "        disc_real = disc(high_res)\n",
    "        disc_fake = disc(fake.detach())\n",
    "        disc_loss_real = bce(\n",
    "            disc_real, torch.ones_like(disc_real) - 0.1 * torch.rand_like(disc_real)\n",
    "        )\n",
    "        disc_loss_fake = bce(disc_fake, torch.zeros_like(disc_fake))\n",
    "        loss_disc = disc_loss_fake + disc_loss_real\n",
    "\n",
    "        opt_disc.zero_grad()\n",
    "        loss_disc.backward()\n",
    "        opt_disc.step()\n",
    "\n",
    "        # Train Generator: min log(1 - D(G(z))) <-> max log(D(G(z))\n",
    "        disc_fake = disc(fake)\n",
    "        #l2_loss = mse(fake, high_res)\n",
    "        adversarial_loss = 1e-3 * bce(disc_fake, torch.ones_like(disc_fake))\n",
    "        loss_for_vgg = 0.006 * vgg_loss(fake, high_res)\n",
    "        gen_loss = loss_for_vgg + adversarial_loss\n",
    "\n",
    "        opt_gen.zero_grad()\n",
    "        gen_loss.backward()\n",
    "        opt_gen.step()\n",
    "\n",
    "        if idx % 200 == 0:\n",
    "            plot_examples(\"test_images/\", gen)\n",
    "\n",
    "\n",
    "def main():\n",
    "    dataset = MyImageFolder(root_dir=\"data/\")\n",
    "    loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        pin_memory=True,\n",
    "        num_workers=NUM_WORKERS,\n",
    "    )\n",
    "    gen = Generator(in_channels=3).to(DEVICE)\n",
    "    disc = Discriminator(in_channels=3).to(DEVICE)\n",
    "    opt_gen = optim.Adam(gen.parameters(), lr=LEARNING_RATE, betas=(0.9, 0.999))\n",
    "    opt_disc = optim.Adam(disc.parameters(), lr=LEARNING_RATE, betas=(0.9, 0.999))\n",
    "    mse = nn.MSELoss()\n",
    "    bce = nn.BCEWithLogitsLoss()\n",
    "    vgg_loss = VGGLoss()\n",
    "\n",
    "    if LOAD_MODEL:\n",
    "        load_checkpoint(\n",
    "            CHECKPOINT_GEN,\n",
    "            gen,\n",
    "            opt_gen,\n",
    "            LEARNING_RATE,\n",
    "        )\n",
    "        load_checkpoint(\n",
    "           CHECKPOINT_DISC, disc, opt_disc, LEARNING_RATE,\n",
    "        )\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        train_fn(loader, disc, gen, opt_gen, opt_disc, mse, bce, vgg_loss)\n",
    "\n",
    "        if SAVE_MODEL:\n",
    "            save_checkpoint(gen, opt_gen, filename=CHECKPOINT_GEN)\n",
    "            save_checkpoint(disc, opt_disc, filename=CHECKPOINT_DISC)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "c8d91fc776e8bbf1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Loading checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\meddi\\AppData\\Local\\Temp\\ipykernel_7392\\2444796023.py:43: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_file, map_location=DEVICE)\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'gen'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mPermissionError\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[24], line 84\u001B[0m\n\u001B[0;32m     80\u001B[0m             save_checkpoint(disc, opt_disc, filename\u001B[38;5;241m=\u001B[39mCHECKPOINT_DISC)\n\u001B[0;32m     83\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__main__\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m---> 84\u001B[0m     \u001B[43mmain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[24], line 65\u001B[0m, in \u001B[0;36mmain\u001B[1;34m()\u001B[0m\n\u001B[0;32m     62\u001B[0m vgg_loss \u001B[38;5;241m=\u001B[39m VGGLoss()\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m LOAD_MODEL:\n\u001B[1;32m---> 65\u001B[0m     \u001B[43mload_checkpoint\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     66\u001B[0m \u001B[43m        \u001B[49m\u001B[43mCHECKPOINT_GEN\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     67\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgen\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     68\u001B[0m \u001B[43m        \u001B[49m\u001B[43mopt_gen\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     69\u001B[0m \u001B[43m        \u001B[49m\u001B[43mLEARNING_RATE\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     70\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     71\u001B[0m     load_checkpoint(\n\u001B[0;32m     72\u001B[0m        CHECKPOINT_DISC, disc, opt_disc, LEARNING_RATE,\n\u001B[0;32m     73\u001B[0m     )\n\u001B[0;32m     75\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(NUM_EPOCHS):\n",
      "Cell \u001B[1;32mIn[19], line 43\u001B[0m, in \u001B[0;36mload_checkpoint\u001B[1;34m(checkpoint_file, model, optimizer, lr)\u001B[0m\n\u001B[0;32m     41\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mload_checkpoint\u001B[39m(checkpoint_file, model, optimizer, lr):\n\u001B[0;32m     42\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m=> Loading checkpoint\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 43\u001B[0m     checkpoint \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcheckpoint_file\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmap_location\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mDEVICE\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     44\u001B[0m     model\u001B[38;5;241m.\u001B[39mload_state_dict(checkpoint[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstate_dict\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[0;32m     45\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mload_state_dict(checkpoint[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moptimizer\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\serialization.py:1065\u001B[0m, in \u001B[0;36mload\u001B[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001B[0m\n\u001B[0;32m   1062\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mencoding\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m pickle_load_args\u001B[38;5;241m.\u001B[39mkeys():\n\u001B[0;32m   1063\u001B[0m     pickle_load_args[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mencoding\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m-> 1065\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43m_open_file_like\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m opened_file:\n\u001B[0;32m   1066\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _is_zipfile(opened_file):\n\u001B[0;32m   1067\u001B[0m         \u001B[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001B[39;00m\n\u001B[0;32m   1068\u001B[0m         \u001B[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001B[39;00m\n\u001B[0;32m   1069\u001B[0m         \u001B[38;5;66;03m# reset back to the original position.\u001B[39;00m\n\u001B[0;32m   1070\u001B[0m         orig_position \u001B[38;5;241m=\u001B[39m opened_file\u001B[38;5;241m.\u001B[39mtell()\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\serialization.py:468\u001B[0m, in \u001B[0;36m_open_file_like\u001B[1;34m(name_or_buffer, mode)\u001B[0m\n\u001B[0;32m    466\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_open_file_like\u001B[39m(name_or_buffer, mode):\n\u001B[0;32m    467\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _is_path(name_or_buffer):\n\u001B[1;32m--> 468\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_open_file\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    469\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    470\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mw\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m mode:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\serialization.py:449\u001B[0m, in \u001B[0;36m_open_file.__init__\u001B[1;34m(self, name, mode)\u001B[0m\n\u001B[0;32m    448\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, name, mode):\n\u001B[1;32m--> 449\u001B[0m     \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m)\n",
      "\u001B[1;31mPermissionError\u001B[0m: [Errno 13] Permission denied: 'gen'"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "56b6c325a26a6509"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
